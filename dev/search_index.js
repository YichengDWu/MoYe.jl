var documenterSearchIndex = {"docs":
[{"location":"manual/datamovement/gs/#Global-to-Shared-Memory-Copy","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"","category":"section"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"This tutorial demonstrates how to copy data between global and shared memory using MoYe.jl. We will use the following configuration:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Array size: 2048 x 2048\nBlock size: 32 x 32\nThread size: 32 x 8","category":"page"},{"location":"manual/datamovement/gs/#Copy-Kernel","page":"Global to Shared Memory Copy","title":"Copy Kernel","text":"","category":"section"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"We start with a simple copy kernel:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"using MoYe, Test, CUDA\n\nfunction copy_kernel(dest, src, smemlayout, blocklayout, threadlayout)\n    moye_smem = MoYeSharedArray(eltype(dest), smemlayout) \n\n    moye_dest = MoYeArray(dest)\n    moye_src = MoYeArray(src)\n\n    bM = size(blocklayout, 1)\n    bN = size(blocklayout, 2)\n\n    blocktile_dest = @tile moye_dest (bM, bN) (blockIdx().x, blockIdx().y)\n    blocktile_src  = @tile moye_src  (bM, bN) (blockIdx().x, blockIdx().y)\n\n    threadtile_dest = @parallelize blocktile_dest threadlayout threadIdx().x\n    threadtile_src  = @parallelize blocktile_src  threadlayout threadIdx().x\n    threadtile_smem = @parallelize moye_smem      threadlayout threadIdx().x\n\n    for i in eachindex(threadtile_smem)\n        threadtile_smem[i] = threadtile_src[i]\n    end\n    \n    for i in eachindex(threadtile_dest)\n        threadtile_dest[i] = threadtile_smem[i]\n    end\n    return nothing\nend\n\nfunction test_copy_async(M, N)\n    a = CUDA.rand(Float32, M, N)\n    b = CUDA.rand(Float32, M, N)\n\n    blocklayout = @Layout (32, 32) # 32x32 elements per block\n    smemlayout = @Layout (32, 32)  # 32x32 elements in shared memory\n    threadlayout = @Layout (32, 8) # 32x8 threads per block\n\n    bM = size(blocklayout, 1)\n    bN = size(blocklayout, 2)\n\n    blocks = (cld(M, bM), cld(N, bN))\n    threads = Int(size(threadlayout))\n\n    @cuda blocks=blocks threads=threads copy_kernel(a, b, smemlayout, blocklayout, threadlayout)\n    CUDA.synchronize()\n    @test a == b\nend\n\ntest_copy_async(2048, 2048)","category":"page"},{"location":"manual/datamovement/gs/#Code-Explanation","page":"Global to Shared Memory Copy","title":"Code Explanation","text":"","category":"section"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"The device function performs the following steps:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Allocate shared memory: MoYeSharedArray allocates shared memory with a static layout.\nWrap arrays: The destination and source arrays are wrapped with dynamic layouts.\nGet block size: Get the size of each block in the grid (bM and bN).\nCreate local tiles: Create local tiles for the destination and source arrays using @tile.\nPartition tiles: Partition the local tiles into thread tiles using @parallelize.\nCopy to shared memory: Copy data from the source thread tile to the shared memory thread tile.\nSynchronize threads.\nCopy to destination: Copy data from the shared memory thread tile to the destination thread tile.","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"The host function tests the copy_kernel function:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Define dimensions: Define the dimensions M and N for the source and destination arrays.\nCreate GPU arrays: Create random GPU arrays a and b.\nDefine layouts: Define the block and thread layouts using @Layout.\nCalculate grid size: Calculate the number of blocks in the grid using cld.","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Key points to note:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"@tile ensures that all blocks cover the entire array.\nEach block contains 32x32 elements, but we have 32x8 threads per block, so each thread processes 4 elements. The code @parallelize blocktile_dest threadlayout threadIdx().x returns the set of elements that the current thread is responsible for, which is an array of length 4.\nOnce tiling is complete, we can perform computations as if we were working with a regular array:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"for i in eachindex(threadtile_smem)\n    threadtile_smem[i] = threadtile_src[i]\nend","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"MoYe.jl handles the index bookkeeping implicitly, allowing you to focus on the computation.","category":"page"},{"location":"manual/datamovement/gs/#Using-copyto!","page":"Global to Shared Memory Copy","title":"Using copyto!","text":"","category":"section"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"You can also use copyto! for static MoYeArrays. This function automatically calls cp.async when copying from global to shared memory (requires sm_80 or higher) and performs automatic vectorization when possible.","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Here is the kernel using copyto!:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"function copy_kernel(dest, src, smemlayout, blocklayout, threadlayout)\n    moye_smem = MoYeSharedArray(eltype(dest), smemlayout) \n\n    moye_dest = MoYeArray(dest)\n    moye_src = MoYeArray(src)\n\n    bM = size(blocklayout, 1)\n    bN = size(blocklayout, 2)\n\n    blocktile_dest = @tile moye_dest (bM, bN) (blockIdx().x, blockIdx().y)\n    blocktile_src  = @tile moye_src  (bM, bN) (blockIdx().x, blockIdx().y)\n\n    threadtile_dest = @parallelize blocktile_dest threadlayout threadIdx().x\n    threadtile_src  = @parallelize blocktile_src  threadlayout threadIdx().x\n    threadtile_smem = @parallelize moye_smem      threadlayout threadIdx().x\n\n    copyto!(threadtile_smem, threadtile_src)\n    cp_async_wait()\n    copyto!(threadtile_dest, threadtile_smem)\n\n    return nothing\nend","category":"page"},{"location":"manual/datamovement/gs/#Padding-Shared-Memory","page":"Global to Shared Memory Copy","title":"Padding Shared Memory","text":"","category":"section"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"In the above code, the shared memory layout is the same as the block layout. However, it is often necessary to pad the shared array to avoid bank conflicts. This can be done by changing one line of code:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"smemlayout = @Layout (32, 32) (1, 31)  # Pad one row","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Note that the kernel will recompile for different static layout parameters.","category":"page"},{"location":"manual/datamovement/gs/#Transpose-Kernel","page":"Global to Shared Memory Copy","title":"Transpose Kernel","text":"","category":"section"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"Now, let's look at a transpose kernel:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"function transpose_kernel(dest, src, smemlayout, blocklayout, threadlayout)\n    moye_smem = MoYeSharedArray(eltype(dest), smemlayout) \n\n    moye_src = MoYeArray(src)\n    moye_dest = MoYeArray(dest)\n\n    bM = size(blocklayout, 1)\n    bN = size(blocklayout, 2)\n\n    blocktile_src  = @tile moye_src  (bM, bN) (blockIdx().x, blockIdx().y)\n    blocktile_dest = @tile moye_dest (bN, bM) (blockIdx().y, blockIdx().x)\n\n    threadtile_dest = @parallelize blocktile_dest threadlayout threadIdx().x\n    threadtile_src  = @parallelize blocktile_src  threadlayout threadIdx().x\n    threadtile_smem = @parallelize moye_smem      threadlayout threadIdx().x\n\n    copyto!(threadtile_smem, threadtile_src)\n    cp_async_wait()\n    sync_threads()\n\n    moye_smem′ = MoYe.transpose(moye_smem)\n    threadtile_smem′ = @parallelize moye_smem′ threadlayout threadIdx().x\n\n    copyto!(threadtile_dest, threadtile_smem′)\n    return nothing\nend\n\n\nfunction test_transpose(M, N)\n    a = CUDA.rand(Float32, M, N)\n    b = CUDA.rand(Float32, N, M)\n\n    blocklayout = @Layout (32, 32)\n    smemlayout = @Layout (32, 32) (1, 33)\n    threadlayout = @Layout (32, 8)\n\n    bM = size(blocklayout, 1)\n    bN = size(blocklayout, 2)\n\n    blocks = (cld(M, bM), cld(N, bN))\n    threads = Int(size(threadlayout))\n\n    @cuda blocks=blocks threads=threads transpose_kernel(a, b, smemlayout, blocklayout, threadlayout)\n    CUDA.synchronize()\n    @test a == transpose(b)\nend\n\ntest_transpose(2048, 2048)","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"This is almost identical to the copy kernel, but we transpose the shared memory by transposing its layout:","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"    moye_smem′ = MoYe.transpose(moye_smem)","category":"page"},{"location":"manual/datamovement/gs/","page":"Global to Shared Memory Copy","title":"Global to Shared Memory Copy","text":"We then compute the new thread tiles. Note that each thread will now work on different elements, so we need to call sync_threads().","category":"page"},{"location":"manual/array/#MoYeArray","page":"Array","title":"MoYeArray","text":"","category":"section"},{"location":"manual/array/","page":"Array","title":"Array","text":"MoYeArray leverages the Layout to create specialized arrays. For example, we can create a FillArray-like array:","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"using MoYe\nMoYeArray{Float64}(one, @Layout((3,4), (0, 0)))\nans.engine","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"As you can see, the array contains only one element. The physical length of the array is calculated by cosize:","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"cosize(@Layout((3,4), (0, 0)))","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"The underlying implementation of MoYeArray results in periodic linear indexing:","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"function f()\n    B = MoYeArray([1,2,3], @Layout((3,), (1,)))\n    @show @inbounds B[4], B[5], B[6], B[7]\nend\nf();","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"We can also easily create a BlockArray:","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"data = collect(1:48);\nB = MoYeArray(data, @Layout(((2,3), (2,4)), ((1, 16), (2, 4))))","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"Here, we created a 2x3 block array with 2x4 blocks. The first mode is the block index, and the second mode is the index within the block.","category":"page"},{"location":"manual/array/#Slicing","page":"Array","title":"Slicing","text":"","category":"section"},{"location":"manual/array/","page":"Array","title":"Array","text":"It is required to use view(a, ids...) or @view a[ids...] for slicing:","category":"page"},{"location":"manual/array/","page":"Array","title":"Array","text":"data = [i for i in 1:164];\na = MoYeArray(data, ((_3, 2), (2, _5, _2)), ((4,1), (_2, 13, 100)))\nb = @view a[2, :]","category":"page"},{"location":"api/tiling/#Index","page":"Tiling","title":"Index","text":"","category":"section"},{"location":"api/tiling/","page":"Tiling","title":"Tiling","text":"Pages = [\"tiling.md\"]","category":"page"},{"location":"api/tiling/#MoYe.@tile","page":"Tiling","title":"MoYe.@tile","text":"@tile x::MoYeArray threadgroup_shape::Tile threadgroup_coord::Tuple\n\nPartition x with threadgroup_shape. Return the view of the entries of x that the thread group at threadgroup_coord will work on.\n\nExamples\n\njulia> a = MoYeArray(pointer([i for i in 1:48]), @Layout((6,8)))\n6×8 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{6}, Static.StaticInt{8}}, Tuple{Static.StaticInt{1}, Static.StaticInt{6}}}} with indices _1:_6×_1:_8:\n 1   7  13  19  25  31  37  43\n 2   8  14  20  26  32  38  44\n 3   9  15  21  27  33  39  45\n 4  10  16  22  28  34  40  46\n 5  11  17  23  29  35  41  47\n 6  12  18  24  30  36  42  48\n\njulia> @tile a (_2, _2) (1, 1)\n2×2 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{StaticInt{2}, StaticInt{2}}, Tuple{StaticInt{1}, StaticInt{6}}}}:\n 1  7\n 2  8\n\n\n\n\n\n\n","category":"macro"},{"location":"api/tiling/#MoYe.@parallelize","page":"Tiling","title":"MoYe.@parallelize","text":"@parallelize x::MoYeArray threadgroup_layout::Layout thread_idx::Int\n\nPartition x with size(threadgroup_layout) threads, and return the view of the entries that the thread at thread_idx will work on.\n\nExamples\n\nSay we have a MoYeArray x of shape (6, 8) and 4 threads of shape (2, 2). We would like to  partition x with the 4 threads and get a view of the entries that the first thread will work on. We can do this by calling @parallelize(x, (2, 2), 1).\n\njulia> a = MoYeArray(pointer([i for i in 1:48]), @Layout((6,8)))\n6×8 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{6}, Static.StaticInt{8}}, Tuple{Static.StaticInt{1}, Static.StaticInt{6}}}}:\n 1   7  13  19  25  31  37  43\n 2   8  14  20  26  32  38  44\n 3   9  15  21  27  33  39  45\n 4  10  16  22  28  34  40  46\n 5  11  17  23  29  35  41  47\n 6  12  18  24  30  36  42  48\n\njulia> @parallelize a (_2, _2) (1, 1)\n3×4 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{3}, Static.StaticInt{4}}, Tuple{Static.StaticInt{2}, Static.StaticInt{12}}}}:\n 1  13  25  37\n 3  15  27  39\n 5  17  29  41\n\nYou can also pass in a thread layout and a thread id to get the tile:\n\njulia> @parallelize a @Layout((2,2), (1, 2)) 2\n3×4 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{StaticInt{3}, StaticInt{4}}, Tuple{StaticInt{2}, StaticInt{12}}}}:\n 2  14  26  38\n 4  16  28  40\n 6  18  30  42\n\njulia> @parallelize a @Layout((2,2), (2, 1)) 2\n3×4 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{StaticInt{3}, StaticInt{4}}, Tuple{StaticInt{2}, StaticInt{12}}}}:\n  7  19  31  43\n  9  21  33  45\n 11  23  35  47\n\n\n\n\n\n","category":"macro"},{"location":"manual/async/#Asynchronous-Memory-Copies","page":"Memcpy Async","title":"Asynchronous Memory Copies","text":"","category":"section"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"The NVIDIA Ampere architecture introduced memcpy_async, a feature that allows for asynchronous data copies between GPU global and shared memory. This frees up threads from managing data movement, allowing them to focus on computation.","category":"page"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"To use this feature, we change the TiledCopy to the following:","category":"page"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"copy_A = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{TA}, TA}(),\n                                @Layout((32, 8)),\n                                @Layout((1, 1)))\ncopy_B = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{TB}, TB}(),\n                                    @Layout((32, 8)),\n                                    @Layout((1, 1)))","category":"page"},{"location":"manual/async/#Updated-Kernel","page":"Memcpy Async","title":"Updated Kernel","text":"","category":"section"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"function matmul_kernel(A, sA_layout, copy_A,\n                       B, sB_layout, copy_B,\n                       C, mma_C)\n    sA = MoYeSharedArray(eltype(A), sA_layout)\n    sB = MoYeSharedArray(eltype(B), sB_layout)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Copy partition\n    thr_copy_a = get_slice(copy_A, threadIdx().x)      \n    tAgA = partition_S(thr_copy_a, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(thr_copy_a, sA)                 # (CPY, CPY_M, CPY_K)\n\n    thr_copy_b = get_slice(copy_B, threadIdx().x)\n    tBgB = partition_S(thr_copy_b, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(thr_copy_b, sB)                 # (CPY, CPY_N, CPY_K)\n\n    # MMA partition\n    thr_mma = get_slice(mma_C, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                    # (MMA, MMA_M, MMA_K)\n    tCsB = partition_B(thr_mma, sB)                    # (MMA, MMA_M, MMA_K)\n    tCgC = partition_C(thr_mma, gC)                    # (MMA, MMA_M, MMA_N)\n\n    # Accumulator\n    tCrC = make_fragment_C(thr_mma, tCgC)\n    zeros!(tCrC)\n\n    for k in axes(tAgA, 4)\n        copyto!(copy_A, tAsA, view(tAgA, :, :, :, k))\n        copyto!(copy_B, tBsB, view(tBgB, :, :, :, k))\n        \n        cp_async_wait()\n\n        @gc_preserve gemm!(mma_C, tCrC, tCsA, tCsB, tCrC)\n        sync_threads()\n    end\n\n\n    copyto!(tCgC, tCrC)\n    return nothing\nend\n\nfunction matmul(A, B, C)\n    bM = _128\n    bN = _128\n    bK = _8\n    \n    sA_layout = make_layout((bM, bK), (_1, bM + _1))\n    sB_layout = make_layout((bN, bK), (_1, bN + _1))\n\n    TA = eltype(A)\n    TB = eltype(B)\n    TC = eltype(C)\n\t\n    copy_A = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{TA}, TA}(),\n                                    @Layout((32, 8)),\n                                    @Layout((1, 1)))\n    copy_B = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{TB}, TB}(),\n                                        @Layout((32, 8)),\n                                        @Layout((1, 1)))\n\n    mma_C = make_tiled_mma(UniversalFMA{TA,TB, TC}(), # MMA operation\n                           @Layout((32,8)))          # Atom layout\n\n    threads = Int(size(mma_C))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, copy_A,\n                                                      B, sB_layout, copy_B,\n                                                      C, mma_C)\nend\n\n\nfunction test()\n    A =  CUDA.randn(Float32, 2048, 256)\n    B =  CUDA.randn(Float32, 2048, 256)\n    C =  CUDA.randn(Float32, 2048, 2048)\n    matmul(A, B, C)\n    CUDA.synchronize()\n    @test C == A * B'\n    CUDA.unsafe_free!(A)\n    CUDA.unsafe_free!(B)\n    CUDA.unsafe_free!(C)\nend\n\ntest()","category":"page"},{"location":"manual/async/#Vectorized-Copy","page":"Memcpy Async","title":"Vectorized Copy","text":"","category":"section"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"We can enable vectorized copies from global to shared memory by changing CPOP_ASYNC_CACHEALWAYS{TA} and CPOP_ASYNC_CACHEALWAYS{TB} to CPOP_ASYNC_CACHEALWAYS{Float64}. However, this will result in a memory misalignment error because we padded sA and sB by one row. The element at [1,2] is not aligned to 8 bytes as required by the copy_async instruction.","category":"page"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"To fix this, we need to adjust the padding:","category":"page"},{"location":"manual/async/","page":"Memcpy Async","title":"Memcpy Async","text":"sA_layout = make_layout((bM, bK), (_1, bM + _2))\nsB_layout = make_layout((bN, bK), (_1, bN + _2))","category":"page"},{"location":"manual/broadcast/#Broadcasting","page":"Broadcasting","title":"Broadcasting","text":"","category":"section"},{"location":"manual/broadcast/","page":"Broadcasting","title":"Broadcasting","text":"Broadcasting is a powerful feature that allows you to perform element-wise operations on arrays of different shapes and sizes. In MoYe.jl, broadcasting is defined for MoYeArrays with static sizes.","category":"page"},{"location":"manual/broadcast/#In-Place-vs.-Out-of-Place-Broadcasting","page":"Broadcasting","title":"In-Place vs. Out-of-Place Broadcasting","text":"","category":"section"},{"location":"manual/broadcast/","page":"Broadcasting","title":"Broadcasting","text":"In-place broadcasting (.=, .+=, etc.) modifies the original array and preserves its layout.\nOut-of-place broadcasting (., +, etc.) returns a new array with a compact layout, the same shape, and the same stride order.","category":"page"},{"location":"manual/broadcast/","page":"Broadcasting","title":"Broadcasting","text":"using MoYe\na = MoYeArray{Float64}(undef, @Layout((3,2), (2,1)))\nfill!(a, 1.0);\na .* 3\na .+ a","category":"page"},{"location":"manual/broadcast/","page":"Broadcasting","title":"Broadcasting","text":"b = MoYeArray{Float64}(undef, @Layout((3,), (2,))) |> zeros!; # Create a vector\na .- b ","category":"page"},{"location":"manual/broadcast/#Broadcasting-on-the-GPU","page":"Broadcasting","title":"Broadcasting on the GPU","text":"","category":"section"},{"location":"manual/broadcast/","page":"Broadcasting","title":"Broadcasting","text":"In-place broadcasting on the GPU works seamlessly:","category":"page"},{"location":"manual/broadcast/","page":"Broadcasting","title":"Broadcasting","text":"julia> function f()\n           a = MoYeArray{Float64}(undef, @Layout((3,2)))\n           fill!(a, one(eltype(a)))\n           a .= a .* 2\n           @cushow sum(a)\n           b = CUDA.exp.(a)\n           @cushow sum(b)\n           return nothing\n       end\nf (generic function with 1 method)\n\njulia> @cuda f()\nsum(a) = 12.000000\nsum(b) = 44.334337\nCUDA.HostKernel{typeof(f), Tuple{}}(f, CuFunction(Ptr{CUDA.CUfunc_st} @0x0000026e00ca1af0, CuModule(Ptr{CUDA.CUmod_st} @0x0000026e15cfc900, CuContext(0x0000026da1fff8b0, instance e5a1871b578f5adb))), CUDA.KernelState(Ptr{Nothing} @0x0000000204e00000))","category":"page"},{"location":"api/array/#MoYeArray","page":"MoYeArray","title":"MoYeArray","text":"","category":"section"},{"location":"api/array/#Index","page":"MoYeArray","title":"Index","text":"","category":"section"},{"location":"api/array/","page":"MoYeArray","title":"MoYeArray","text":"Pages = [\"array.md\"]","category":"page"},{"location":"api/array/#MoYe.ViewEngine","page":"MoYeArray","title":"MoYe.ViewEngine","text":"ViewEngine{T, P}\n\nA wrapper of a pointer. P is the type of the pointer.\n\n\n\n\n\n","category":"type"},{"location":"api/array/#MoYe.ArrayEngine","page":"MoYeArray","title":"MoYe.ArrayEngine","text":"ArrayEngine{T, L} <: DenseVector{T}\n\nA owning and mutable vector of type T with static length L.\n\nExamples\n\njulia> x = ArrayEngine{Float32}(undef, _3)\n3-element ArrayEngine{Float32, 3}:\n -9.8271385f-36\n  7.57f-43\n -9.8271385f-36\n\njulia> x[1] = 10f0\n10.0f0\n\njulia> x\n3-element ArrayEngine{Float32, 3}:\n 10.0\n  7.57f-43\n -9.8271385f-36\n\n\n\n\n\n","category":"type"},{"location":"api/array/#MoYe.MoYeArray","page":"MoYeArray","title":"MoYe.MoYeArray","text":"MoYeArray(engine::Engine, layout::Layout)\nMoYeArray{T}(::UndefInitializer, layout::StaticLayout)\nMoYeArray(ptr, layout::Layout)\n\nCreate a MoYeArray from an engine and a layout. See also ArrayEngine and ViewEngine.\n\nExamples\n\njulia> slayout = @Layout (5, 2);\n\njulia> array_engine = ArrayEngine{Float32}(undef, cosize(slayout)); # owning array\n\njulia> MoYeArray(array_engine, slayout)\n5×2 MoYeArray{Float32, 2, ArrayEngine{Float32, 10}, Layout{2, Tuple{Static.StaticInt{5}, Static.StaticInt{2}}, Tuple{Static.StaticInt{1}, Static.StaticInt{5}}}}:\n -3.24118f12   0.0\n  7.57f-43     0.0\n  0.0          0.0\n  0.0          0.0\n  7.89217f-40  0.0\n\njulia>  MoYeArray{Float32}(undef, slayout)\n5×2 MoYeArray{Float32, 2, ArrayEngine{Float32, 10}, Layout{2, Tuple{Static.StaticInt{5}, Static.StaticInt{2}}, Tuple{Static.StaticInt{1}, Static.StaticInt{5}}}}:\n  4.0f-45    7.57f-43\n  0.0        0.0\n -1.81623f7  0.0\n  7.57f-43   0.0\n -1.81623f7  0.0\n\njulia> A = ones(10);\n\njulia> MoYeArray(pointer(A), slayout) # non-owning array\n5×2 MoYeArray{Float64, 2, ViewEngine{Float64, Ptr{Float64}}, Layout{2, Tuple{Static.StaticInt{5}, Static.StaticInt{2}}, Tuple{Static.StaticInt{1}, Static.StaticInt{5}}}}:\n 1.0  1.0\n 1.0  1.0\n 1.0  1.0\n 1.0  1.0\n 1.0  1.0\n\njulia> function test_alloc()          # when powered by a ArrayEngine, MoYeArray is stack-allocated\n    slayout = @Layout (2, 3)          # and mutable\n    x = MoYeArray{Float32}(undef, slayout)\n    fill!(x, 1.0f0)\n    return sum(x)\nend\ntest_alloc (generic function with 2 methods)\n\njulia> @allocated(test_alloc())\n0\n\n\n\n\n\n","category":"type"},{"location":"api/array/#MoYe.recast","page":"MoYeArray","title":"MoYe.recast","text":"recast(::Type{NewType}, x::MoYeArray{OldType}) -> MoYeArray{NewType}\n\nRecast the element type of a MoYeArray. This is similar to Base.reinterpret, but dose all the computation at compile time, if possible.\n\nExamples\n\njulia> x = MoYeArray{Int32}(undef, @Layout((2,3)))\n2×3 MoYeArray{Int32, 2, ArrayEngine{Int32, 6}, Layout{2, Tuple{Static.StaticInt{2}, Static.StaticInt{3}}, Tuple{Static.StaticInt{1}, Static.StaticInt{2}}}}:\n -1948408944           0  2\n         514  -268435456  0\n\njulia> x2 = recast(Int16, x)\n4×3 MoYeArray{Int16, 2, ViewEngine{Int16, Ptr{Int16}}, Layout{2, Tuple{Static.StaticInt{4}, Static.StaticInt{3}}, Tuple{Static.StaticInt{1}, Static.StaticInt{4}}}}:\n -23664      0  2\n -29731      0  0\n    514      0  0\n      0  -4096  0\n\njulia> x3 = recast(Int64, x)\n1×3 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{1}, Static.StaticInt{3}}, Tuple{Static.StaticInt{1}, Static.StaticInt{1}}}}:\n 2209959748496  -1152921504606846976  2\n\n\n\n\n\n","category":"function"},{"location":"api/array/#MoYe.zeros!","page":"MoYeArray","title":"MoYe.zeros!","text":"zeros!(x::MoYeArray)\n\nFill x with zeros.\n\n\n\n\n\n","category":"function"},{"location":"manual/matmul/#Matrix-Multiplication","page":"MatMul","title":"Matrix Multiplication","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"(Image: matmul)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"This tutorial explores matrix multiplication using MoYe.jl, specifically computing the product C = A times B^T. Here, A is an (M K) matrix, B is a (K N) matrix, and C is an (M N) matrix.","category":"page"},{"location":"manual/matmul/#Tiling-Strategy","page":"MatMul","title":"Tiling Strategy","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"We divide the computation among thread blocks, where each block computes a tile of C of size (bM, bN). The tile index is determined by (blockIdx().x, blockIdx().y).","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Computing a tile of C requires a corresponding tile of A of shape (bM, K) and a tile of B of shape (bN, K). To minimize global memory access, we further partition A and B along the K dimension into smaller tiles of size (bM, bK) and (bN, bK), respectively. These smaller tiles are loaded into shared memory sequentially.","category":"page"},{"location":"manual/matmul/#Global-Memory-Partitioning","page":"MatMul","title":"Global Memory Partitioning","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"The global memory partitioning is defined as follows:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"gC = @tile C (bM, bN) (blockIdx().x, blockIdx().y) # (bM, bN)\ngA = @tile A (bM, bK) (blockIdx().x, :)            # (bM, bK, K/bK)\ngB = @tile B (bN, bK) (blockIdx().y, :)            # (bN, bK, K/bK)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Refer to @tile for more details on the syntax. Here, gA represents a tile of A in global memory. We then loop over the last dimension of gA and gB (denoted as k) to load them into shared memory.","category":"page"},{"location":"manual/matmul/#Shared-Memory-Allocation","page":"MatMul","title":"Shared Memory Allocation","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Shared memory is allocated using MoYeSharedArray:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"sA = MoYeSharedArray(eltype(gA), sA_layout) # (bM, bK)\nsB = MoYeSharedArray(eltype(gB), sB_layout) # (bN, bK)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"MoYeSharedArray automatically allocates shared memory of size cosize(sA_layout) + cosize(sB_layout) and returns a MoYeArray. The layouts sA_layout and sB_layout are predefined at compile time.","category":"page"},{"location":"manual/matmul/#Thread-Partitioning","page":"MatMul","title":"Thread Partitioning","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"We then define how thread groups copy data from global to shared memory. For example:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"tA = @Layout (32, 8)\ntB = @Layout (32, 8)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"This creates a 32x8 thread group in column-major format. We use this to partition the arrays:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"tAgA = @parallelize gA tA threadIdx().x       # (THR_M, THR_K, k)\ntBgB = @parallelize gB tB threadIdx().x       # (THR_M, THR_K)\n\ntAsA = @parallelize sA tA threadIdx().x       # (THR_N, THR_K, k)\ntBsB = @parallelize sB tB threadIdx().x       # (THR_N, THR_K)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Refer to @parallelize for more details. After partitioning, copying is straightforward:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"copyto!(tAsA, view(tAgA, :, :, k))\ncopyto!(tBsB, view(tBgB, :, :, k))","category":"page"},{"location":"manual/matmul/#MMA-Computation","page":"MatMul","title":"MMA Computation","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"For the matrix-multiply-accumulate (MMA) computation, we define another thread group layout:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"tC = @Layout (16, 16)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"We then partition gC:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"tCgC = @parallelize gC tC threadIdx().x   # (THR_M, THR_N)\ntCrC = similar(tCgC)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"To reduce memory access to C, we create tCrC in registers to serve as an accumulator. The results are copied back to tCgC after the computation.","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Computing an element in C requires a full row from A and a full column from B:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"tCsA = @parallelize sA tC threadIdx().x (1, :)    # (THR_M, bK)\ntCsB = @parallelize sB tC threadIdx().x (:, 1)    # (THR_N, bK)","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Finally, the matrix multiplication can be performed:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"for k in axes(tCsA, 2)\n    for m in axes(tCsA, 1)\n        for n in axes(tCsB, 1)\n            @inbounds tCrC[m, n] += tCsA[m, k] * tCsB[n, k]\n        end\n    end\nend","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"Alternatively, you can use the gemm! function:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"gemm!(tCrC, tCsA, tCsB, tCrC)","category":"page"},{"location":"manual/matmul/#Complete-Kernel","page":"MatMul","title":"Complete Kernel","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"function matmul_kernel(A, sA_layout, tA,\n                       B, sB_layout, tB,\n                       C, tC)\n    sA = MoYeSharedArray(eltype(A), sA_layout)           # (bM, bK)\n    sB = MoYeSharedArray(eltype(B), sB_layout)           # (bN, bK)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)              # (bM, bN)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)              # (bM, bK, K/bK)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)   # (bN, bK, K/bK)\n\n    # Copy partition\n    tAgA = @parallelize gA tA threadIdx().x               # (THR_M, THR_K, k)\n    tBgB = @parallelize gB tB threadIdx().x               # (THR_M, THR_K)\n    tAsA = @parallelize sA tA threadIdx().x               # (THR_N, THR_K, k)\n    tBsB = @parallelize sB tB threadIdx().x               # (THR_N, THR_K)\n\n    # MMA partition\n    tCsA = @parallelize sA tC threadIdx().x (1, :)        # (THR_M, bK)\n    tCsB = @parallelize sB tC threadIdx().x (:, 1)        # (THR_N, bK)\n    tCgC = @parallelize gC tC threadIdx().x               # (THR_M, THR_N)\n\n    # Accumulator\n    tCrC = similar(tCgC)                                  # (THR_M, THR_N)\n    zeros!(tCrC)\n\n    for k in axes(tAgA, 3)\n        copyto!(tAsA, view(tAgA, :, :, k))\n        copyto!(tBsB, view(tBgB, :, :, k))\n        \n        cp_async_wait()\n        sync_threads()\n\n        @gc_preserve gemm!(tCrC, tCsA, tCsB, tCrC)\n        sync_threads()\n    end\n\n\n    copyto!(tCgC, tCrC)\n    return nothing\nend","category":"page"},{"location":"manual/matmul/#Design-Considerations","page":"MatMul","title":"Design Considerations","text":"","category":"section"},{"location":"manual/matmul/#Shared-Memory-Layout","page":"MatMul","title":"Shared Memory Layout","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"To avoid bank conflicts in shared memory, we pad the layouts by one column:","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"sA_layout = make_layout((bM, bK), (_1, bM + _1))\nsB_layout = make_layout((bN, bK), (_1, bN + _1))","category":"page"},{"location":"manual/matmul/#Thread-Layout-for-MMA","page":"MatMul","title":"Thread Layout for MMA","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"The shape of tC must evenly divide (bM, bN).","category":"page"},{"location":"manual/matmul/#Thread-Layout-for-Copying","page":"MatMul","title":"Thread Layout for Copying","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"To achieve memory coalescing, every 32 threads should access contiguous elements in A and B. The optimal design depends on the memory layout of A and B.","category":"page"},{"location":"manual/matmul/#Host-Function","page":"MatMul","title":"Host Function","text":"","category":"section"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"function matmul(A, B, C)\n    bM = _128\n    bN = _128\n    bK = _8\n    \n    sA_layout = make_layout((bM, bK), (_1, bM + _1))\n    sB_layout = make_layout((bN, bK), (_1, bN + _1))\n\n    tA = @Layout (32, 8)\n    tB = @Layout (32, 8)\n    tC = @Layout (16, 16)\n\n    threads = Int(size(tC))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, tA,\n                                                      B, sB_layout, tB,\n                                                      C, tC)\nend\n\nfunction test()\n    A =  CUDA.randn(Float32, 2048, 256)\n    B =  CUDA.randn(Float32, 2048, 256)\n    C =  CUDA.randn(Float32, 2048, 2048)\n    matmul(A, B, C)\n    CUDA.synchronize()\n    @test C == A * B'\n    CUDA.unsafe_free!(A)\n    CUDA.unsafe_free!(B)\n    CUDA.unsafe_free!(C)\nend\n\ntest()","category":"page"},{"location":"manual/matmul/","page":"MatMul","title":"MatMul","text":"This concludes the guide to implementing matrix multiplication with MoYe.jl, focusing on efficient memory management and tiling strategies.","category":"page"},{"location":"manual/tiled_matmul/#Tiled-Matmul","page":"TiledCopy & TiledMMA","title":"Tiled Matmul","text":"","category":"section"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"While @tile and @parallelize are powerful tools for data manipulation, they can be cumbersome. TiledCopy and TiledMMA simplify this process.","category":"page"},{"location":"manual/tiled_matmul/#Tiled-Copy","page":"TiledCopy & TiledMMA","title":"Tiled Copy","text":"","category":"section"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"TiledCopy streamlines data transfer between arrays. Consider an example where six threads copy a 4x9 src array to a dst array of the same shape. The mapping of logical coordinates to thread IDs is as follows:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"1 1 1 2 2 2 3 3 3\n1 1 1 2 2 2 3 3 3\n4 4 4 5 5 5 6 6 6\n4 4 4 5 5 5 6 6 6","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Each thread is assigned a data segment defined by val_layout (2,3):(1,2), while the thread group operates within thr_layout (2,3):(3,1).","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"First, initialize the arrays:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"using MoYe\nsrc_buffer = collect(1:36) .* 0.1;\nsrc = MoYeArray(src_buffer, @Layout((4,9)))\ndst_buffer = zeros(36);\ndst = MoYeArray(dst_buffer, make_layout((_4,_9)));","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Next, set up the TiledCopy:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"thr_layout = @Layout (2, 3) (3, 1)\nval_layout = @Layout (2, 3) (1, 2)\ntiled_copy = make_tiled_copy(\n\tCopyAtom{UniversalCopy{Float64}, Float64}(),\n\tthr_layout, \n\tval_layout)","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"The Float64 in CopyAtom specifies the data type. UniversalCopy{Float64} indicates a non-vectorized copy. For vectorized copies, use a type like UInt128:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"tiled_copy_vec = make_tiled_copy(\n\tCopyAtom{UniversalCopy{UInt128}, Float64}(),\n\tthr_layout, \n\tval_layout)","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Note that for vectorized copies, val_layout must have a divisible number of elements.","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Visualize the tiled_copy using print_typst(tiled_copy) in the Typst web app:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"(Image: matmuil)","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"The two tables show the thread distribution for src and dst. PTX instructions may reallocate each thread's data. For example:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"print_typst(make_tiled_copy(MoYe.CopyAtom{LDSM_U32x4_N, UInt16}(),\n                                          @Layout((16,2)), @Layout((2,4))));\n","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"(Image: matmuil)","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"As shown, thr_layout and val_layout are defined on dst. We will revisit ldmatrix when discussing Tensor Cores.","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"After creating the tiled_copy, partition the data:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"thr_idx = 2;\nthr_copy = get_slice(tiled_copy, thr_idx);\ndst_t = partition_D(thr_copy, dst);\ndst_t.layout\nsrc_t = partition_S(thr_copy, src);\nsrc_t.layout\ncopyto!(tiled_copy, dst_t, src_t);\ndst","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"The second thread has now completed its copy. The shape of dst_t is (CPY, CPY_M, CPY_K), where CPY is the number of vectorized values per thread. In this case, it's 1. Changing to UniversalCopy{UInt128} would alter this.","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"The NVIDIA Ampere architecture supports cuda::memcpy_async for asynchronous data copies between global and shared memory. In older architectures, this required intermediate registers:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"thr_idx = 3;\nthr_copy = get_slice(tiled_copy, thr_idx);\ndst_t = partition_D(thr_copy, dst);\nsrc_t = partition_S(thr_copy, src);\n\ndst_r = make_fragment_like(dst_t);\ncopyto!(tiled_copy, dst_r, src_t);\ncopyto!(tiled_copy, dst_t, dst_r);\ndst","category":"page"},{"location":"manual/tiled_matmul/#TiledMMA","page":"TiledCopy & TiledMMA","title":"TiledMMA","text":"","category":"section"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"TiledMMA simplifies MMA partitions. Invoke make_tiled_mma as follows:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"mma_C = make_tiled_mma(UniversalFMA{TA,TB, TC}(), # MMA operation\n                       @Layout((16,16)))          # Atom layout\n","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"You can replace UniversalFMA with other MMAOp types. View the predefined MMAOps with:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"MoYe.mma_ops_list","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"thr_mma = get_slice(mma_C, threadIdx().x);\ntCsA = partition_A(sA);\ntCsB = partition_B(sB);\ntCgC = partition_C(gC);\n\ntCrC = make_fragment_like(tCgC)","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"These instructions operate on Tensor Cores, which are covered in a later section.","category":"page"},{"location":"manual/tiled_matmul/#Matmul-with-Tiled-Operations","page":"TiledCopy & TiledMMA","title":"Matmul with Tiled Operations","text":"","category":"section"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Now, let's upgrade the matmul_kernel with TiledCopy and TiledMMA.","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"function matmul_kernel(A, sA_layout, copy_A,\n                       B, sB_layout, copy_B,\n                       C, mma_C)\n    sA = MoYeSharedArray(eltype(A), sA_layout)\n    sB = MoYeSharedArray(eltype(B), sB_layout)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n    \n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Copy partition\n    thr_copy_a = get_slice(copy_A, threadIdx().x)      \n    tAgA = partition_S(thr_copy_a, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(thr_copy_a, sA)                 # (CPY, CPY_M, CPY_K)\n    tArA = make_fragment_like(tAsA)                    # (CPY, CPY_M, CPY_K)\n\n    thr_copy_b = get_slice(copy_B, threadIdx().x)\n    tBgB = partition_S(thr_copy_b, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(thr_copy_b, sB)                 # (CPY, CPY_N, CPY_K)\n    tBrB = make_fragment_like(tBsB)                    # (CPY, CPY_N, CPY_K)\n\n    # MMA partition\n    thr_mma = get_slice(mma_C, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                    # (MMA, MMA_M, MMA_K)\n    tCsB = partition_B(thr_mma, sB)                    # (MMA, MMA_M, MMA_K)\n    tCgC = partition_C(thr_mma, gC)                    # (MMA, MMA_M, MMA_N)\n\n    # Overlap copy and compute\n    copyto!(copy_A, tArA, view(tAgA, :, :, :, _1))\n    copyto!(copy_B, tBrB, view(tBgB, :, :, :, _1))\n\n    # Accumulator\n    tCrC = make_fragment_C(thr_mma, tCgC)\n    zeros!(tCrC)\n\n    k_max = size(tAgA, 4)\n    for k in 1:k_max\n        sync_threads()\n        copyto!(tAsA, tArA)\n        copyto!(tBsB, tBrB)\n        sync_threads()\n\n\t    # Load the next tile\n\t    k_next = k < k_max ? k+1 : k\n\t    copyto!(copy_A, tArA, view(tAgA, :, :, :, k_next))\n\t    copyto!(copy_B, tBrB, view(tBgB, :, :, :, k_next))\n\n        @gc_preserve gemm!(mma_C, tCrC, tCsA, tCsB, tCrC)\n    end\n\n    copyto!(tCgC, tCrC)\n    return nothing\nend\n\n\nfunction matmul(A, B, C)\n    bM = _128\n    bN = _128\n    bK = _8\n    \n    sA_layout = make_layout((bM, bK), (_1, bM + _1))\n    sB_layout = make_layout((bN, bK), (_1, bN + _1))\n\n    TA = eltype(A)\n    TB = eltype(B)\n    TC = eltype(C)\n\t\n    copy_A = make_tiled_copy(CopyAtom{UniversalCopy{TA}, TA}(),\n                             @Layout((32, 8)),\n                             @Layout((1, 1)))\n    copy_B = make_tiled_copy(CopyAtom{UniversalCopy{TB}, TB}(),\n                             @Layout((32, 8)),\n                             @Layout((1, 1)))\n\n    mma_C = make_tiled_mma(UniversalFMA{TA,TB, TC}(), # MMA operation\n                           @Layout((32,8)))          # Atom layout\n\n    threads = Int(size(mma_C))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, copy_A,\n                                                      B, sB_layout, copy_B,\n                                                      C, mma_C)\nend\n\nfunction test()\n    A =  CUDA.randn(Float32, 2048, 256)\n    B =  CUDA.randn(Float32, 2048, 256)\n    C =  CUDA.randn(Float32, 2048, 2048)\n    matmul(A, B, C)\n    CUDA.synchronize()\n    @test C == A * B'\n    CUDA.unsafe_free!(A)\n    CUDA.unsafe_free!(B)\n    CUDA.unsafe_free!(C)\nend\n\ntest()","category":"page"},{"location":"manual/tiled_matmul/#Vectorized-Copy-and-Memory-Coalescing","page":"TiledCopy & TiledMMA","title":"Vectorized Copy and Memory Coalescing","text":"","category":"section"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"As mentioned, you can use UniversalCopy{Float64} or UniversalCopy{UInt128} for vectorized copies. However, it is crucial to ensure that memory accesses are coalesced.","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"An uncoalesced copy:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"copy_A = make_tiled_copy(CopyAtom{UniversalCopy{Float64}, TA}(),\n                             @Layout((32, 8)),\n                             @Layout((4, 1)))","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Here, thread 1 loads from [1], [2] and thread 2 loads from [5], [6], which is not coalesced.","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"Coalesced copies:","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"copy_A = make_tiled_copy(CopyAtom{UniversalCopy{Float64}, TA}(),\n                             @Layout((32, 8)),\n                             @Layout((2, 1)))\ncopy_A = make_tiled_copy(CopyAtom{UniversalCopy{UInt128}, TA}(),\n                             @Layout((32, 8)),\n                             @Layout((4, 1)))          ","category":"page"},{"location":"manual/tiled_matmul/","page":"TiledCopy & TiledMMA","title":"TiledCopy & TiledMMA","text":"In these examples, threads access contiguous memory locations, leading to coalesced memory access and better performance.","category":"page"},{"location":"manual/tensor_core/#Tensor-Cores","page":"Tensor Cores","title":"Tensor Cores","text":"","category":"section"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"Tensor Cores are specialized hardware accelerators designed to optimize matrix operations, crucial for deep learning and AI algorithms.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"Enabling Tensor Cores can be as simple as modifying a single line in the matmul_kernel function:","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"mma = make_tiled_mma(MMAOP_8x8x4_F32F16F16F32_NT(), \n                     atom_layout, \n                     tiler)","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"note: Note\nThe NT in MMAOP_8x8x4_F32F16F16F32_NT indicates that matrix A is in M-major order and matrix B is in N-major order.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"Let's explore a minimal example:","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"mma = make_tiled_mma(MMAOP_16x8x8_F32TF32TF32F32_TN())\nprint_typst(mma)","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"(Image: )","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"At first glance, the diagram may seem complex, but the concept is straightforward. Threads collectively load data from matrices A and B according to the specified layout. During the matrix multiply-accumulate (MMA) computation, data is internally shared among threads—a process not transparent to the user. Once the computation is complete, each thread stores the results as dictated by the layout of matrix C.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"function matmul_kernel(A, sA_layout, copy_A,\n                       B, sB_layout, copy_B,\n                       C, mma)\n    sA = MoYeSharedArray(eltype(A), sA_layout)\n    sB = MoYeSharedArray(eltype(B), sB_layout)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Copy partition\n    thr_copy_a = get_slice(copy_A, threadIdx().x)      \n    tAgA = partition_S(thr_copy_a, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(thr_copy_a, sA)                 # (CPY, CPY_M, CPY_K)\n\n    thr_copy_b = get_slice(copy_B, threadIdx().x)\n    tBgB = partition_S(thr_copy_b, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(thr_copy_b, sB)                 # (CPY, CPY_N, CPY_K)\n\n    # MMA partition\n    thr_mma = get_slice(mma, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                    # (MMA, MMA_M, MMA_K)\n    tCsB = partition_B(thr_mma, sB)                    # (MMA, MMA_M, MMA_K)\n    tCgC = partition_C(thr_mma, gC)                    # (MMA, MMA_M, MMA_N)\n\n    tCrA = make_fragment_A(thr_mma, tCsA)              # (MMA, MMA_M, MMA_K)\n    tCrB = make_fragment_B(thr_mma, tCsB) \n    tCrC = make_fragment_C(thr_mma, tCgC)\n    zeros!(tCrC)\n\n    # Copy from global to shared memory\n    copyto!(copy_A, tAsA, view(tAgA, :, :, :, _1))\n    copyto!(copy_B, tBsB, view(tBgB, :, :, :, _1))\n    \n    cp_async_wait()\n\n    # Copy from shared memory to registers\n    copyto!(tCrA, tCsA)\n    copyto!(tCrB, tCsB)\n\n    @gc_preserve gemm!(mma, tCrC, tCrA, tCrB, tCrC)\n\n    copyto!(tCgC, tCrC) \n    @inbounds tCrC[1]  # Compiler bug: must load after copyto!\n\n    return nothing\nend\n\nfunction matmul(A, B, C)\n    bM = _16\n    bN = _8\n    bK = _8\n    \n    sA_layout = make_layout((bM, bK), (_1, bM))\n    sB_layout = make_layout((bN, bK), (bK, _1))\n\n    TA = eltype(A)\n    TB = eltype(B)\n    TC = eltype(C)\n\t\n    copy_A = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{UInt128}, TA}(),\n                             @Layout((4, 8)),\n                             @Layout((4, 1)))\n    copy_B = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{UInt64}, TB}(),\n                             @Layout((8, 4), (4, 1)),\n                             @Layout((1, 2)))\n\n    mma = make_tiled_mma(MMAOP_16x8x8_F32TF32TF32F32_TN()) \n\n    threads = Int(size(mma))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, copy_A, \n                                                      B, sB_layout, copy_B, \n                                                      C, mma)\nend\n\nfunction test()\n    A =  CuArray(reshape(collect(1:16*8) .* 1f0, (16,8))) \n    B =  CuArray(reshape(collect(1:8*8) .* 1f0, (8,8)))\n    C =  CuArray(ones(Float32, (16,8)))\n    matmul(A, B', C)\n    CUDA.synchronize()\n    @test C == A * B\n    CUDA.unsafe_free!(A)\n    CUDA.unsafe_free!(B)\n    CUDA.unsafe_free!(C)\nend","category":"page"},{"location":"manual/tensor_core/#LDMatrix","page":"Tensor Cores","title":"LDMatrix","text":"","category":"section"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"The ldmatrix instruction loads data from shared memory into registers and shuffles it to align with a Tensor Core MMA operation. Given a Tensor Core MMA operation, this shuffling can be \"inverted\" to obtain a TiledCopy for the operation.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"mma = make_tiled_mma(MMAOP_16x8x8_F32TF32TF32F32_TN())\nsmem_copy_A = make_tiled_copy_A(CopyAtom{LDSM_U32x4_N, Float32}(), mma)\nprint_typst(smem_copy_A)","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"(Image: )","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"The resulting layout on the right-hand side matches the layout of A in the mma.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"note: Note\nThe TN in MMAOP_16x8x8_F32TF32TF32F32_TN means that both A and B are in K-major order.\nThe N in LDSM_U32x4_N means the source array is in K-major order.\nldmatrix requires four consecutive threads to load 16 consecutive bytes, meaning the layout of A in shared memory must meet this specification.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"For B:","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"smem_copy_B = make_tiled_copy_B(CopyAtom{LDSM_U32x2_N, Float32}(), mma)\nprint_typst(smem_copy_B)","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"(Image: )","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"note: Note\nThe visualization of B in mma is drawn as (K, N) but as (N, K) in smem_copy_B.","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"We then use smem_copy_A and smem_copy_B to re-tile the shared memory and registers:","category":"page"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"smem_thr_copy_A = get_slice(smem_copy_A, threadIdx().x)\nsmem_thr_copy_B = get_slice(smem_copy_B, threadIdx().x)\ntCsA_retiled = partition_S(smem_thr_copy_A, sA)\ntCsB_retiled = partition_S(smem_thr_copy_B, sB)\ntCrA_retiled = retile_D(smem_thr_copy_A, tCrA)\ntCrB_retiled = retile_D(smem_thr_copy_B, tCrB)","category":"page"},{"location":"manual/tensor_core/#Complete-Code","page":"Tensor Cores","title":"Complete Code","text":"","category":"section"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"function matmul_kernel(A, sA_layout, gmem_copy_A, smem_copy_A,\n                       B, sB_layout, gmem_copy_B, smem_copy_B,\n                       C, mma)\n    sA = MoYeSharedArray(eltype(A), sA_layout)\n    sB = MoYeSharedArray(eltype(B), sB_layout)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Gmem copy partition\n    gmem_thr_copy_a = get_slice(gmem_copy_A, threadIdx().x)      \n    tAgA = partition_S(gmem_thr_copy_a, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(gmem_thr_copy_a, sA)                 # (CPY, CPY_M, CPY_K)\n\n    gmem_thr_copy_b = get_slice(gmem_copy_B, threadIdx().x)\n    tBgB = partition_S(gmem_thr_copy_b, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(gmem_thr_copy_b, sB)                 # (CPY, CPY_N, CPY_K)\n\n    # Copy from global to shared memory\n    copyto!(gmem_copy_A, tAsA, view(tAgA, :, :, :, _1))\n    copyto!(gmem_copy_B, tBsB, view(tBgB, :, :, :, _1))\n\n    # MMA partition\n    thr_mma = get_slice(mma, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                    # (MMA, MMA_M, MMA_K)\n    tCsB = partition_B(thr_mma, sB)                    # (MMA, MMA_M, MMA_K)\n    tCgC = partition_C(thr_mma, gC)                    # (MMA, MMA_M, MMA_N)\n\n    tCrA = make_fragment_A(thr_mma, tCsA)              # (MMA, MMA_M, MMA_K)\n    tCrB = make_fragment_B(thr_mma, tCsB)              # (MMA, MMA_N, MMA_K)\n    tCrC = make_fragment_C(thr_mma, tCgC)              # (MMA, MMA_M, MMA_N)\n    zeros!(tCrC)\n\n    # Retile\n    smem_thr_copy_A = get_slice(smem_copy_A, threadIdx().x)\n    smem_thr_copy_B = get_slice(smem_copy_B, threadIdx().x)\n    tCsA_retiled = partition_S(smem_thr_copy_A, sA)\n    tCsB_retiled = partition_S(smem_thr_copy_B, sB)\n    tCrA_retiled = retile_D(smem_thr_copy_A, tCrA)\n    tCrB_retiled = retile_D(smem_thr_copy_B, tCrB)\n    \n    cp_async_wait()\n\n    # Copy from shared memory to registers\n    copyto!(smem_copy_A, tCrA_retiled, tCsA_retiled)\n    copyto!(smem_copy_B, tCrB_retiled, tCsB_retiled)\n\n    @gc_preserve gemm!(mma, tCrC, tCrA, tCrB, tCrC)\n\n    copyto!(tCgC, tCrC) \n    @inbounds tCrC[1]  # Compiler bug: must load after copyto!\n\n    return nothing\nend\n\n\nfunction matmul(A, B, C)\n    bM = _16\n    bN = _8\n    bK = _8\n    \n    sA_layout = make_layout((bM, bK), (_1, bM))\n    sB_layout = make_layout((bN, bK), (bK, _1))\n\n    TA = eltype(A)\n    TB = eltype(B)\n    TC = eltype(C)\n\t\n    gmem_copy_A = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{UInt128}, TA}(),\n                                  @Layout((4, 8)),\n                                  @Layout((4, 1)))\n    gmem_copy_B = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{UInt64}, TB}(),\n                                  @Layout((8, 4), (4, 1)),\n                                  @Layout((1, 2)))\n\n    mma = make_tiled_mma(MMAOP_16x8x8_F32TF32TF32F32_TN()) \n\n    # Note: A is M-major, so we can only use `UniversalCopy`\n    smem_copy_A =  make_tiled_copy_A(CopyAtom{UniversalCopy{TA}, TA}(), mma)\n    smem_copy_B =  make_tiled_copy_B(CopyAtom{LDSM_U32x2_N, TB}(), mma)\n\n    threads = Int(size(mma))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, gmem_copy_A, smem_copy_A,\n                                                      B, sB_layout, gmem_copy_B, smem_copy_B,\n                                                      C, mma)\nend","category":"page"},{"location":"manual/tensor_core/#Double-Buffering","page":"Tensor Cores","title":"Double Buffering","text":"","category":"section"},{"location":"manual/tensor_core/","page":"Tensor Cores","title":"Tensor Cores","text":"@views function matmul_kernel(A, sA_layout, gmem_copy_A, smem_copy_A,\n                              B, sB_layout, gmem_copy_B, smem_copy_B,\n                              C, mma)\n    sA = MoYeSharedArray(eltype(A), sA_layout)        # (bM, bK, 2)\n    sB = MoYeSharedArray(eltype(B), sB_layout)        # (bN, bK, 2)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Gmem copy partition\n    gmem_thr_copy_A = get_slice(gmem_copy_A, threadIdx().x)      \n    tAgA = partition_S(gmem_thr_copy_A, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(gmem_thr_copy_A, sA)                 # (CPY, CPY_M, CPY_K, 2)\n\n    gmem_thr_copy_B = get_slice(gmem_copy_B, threadIdx().x)\n    tBgB = partition_S(gmem_thr_copy_B, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(gmem_thr_copy_B, sB)                 # (CPY, CPY_N, CPY_K, 2)\n\n    # Copy gmem to smem for k_tile=1\n    copyto!(gmem_copy_A, tAsA[:, :, :, _1], tAgA[:, :, :, _1])\n    copyto!(gmem_copy_B, tBsB[:, :, :, _1], tBgB[:, :, :, _1])\n\n    # MMA partition\n    thr_mma = get_slice(mma, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                         # (MMA, MMA_M, MMA_K, 2)\n    tCsB = partition_B(thr_mma, sB)                         # (MMA, MMA_M, MMA_K, 2)\n    tCgC = partition_C(thr_mma, gC)                         # (MMA, MMA_M, MMA_N)\n\n    tCrA = make_fragment_A(thr_mma, tCsA[:, :, :, _1])      # (MMA, MMA_M, MMA_K)\n    tCrB = make_fragment_B(thr_mma, tCsB[:, :, :, _1])      # (MMA, MMA_N, MMA_K)\n    tCrC = make_fragment_C(thr_mma, tCgC)                   # (MMA, MMA_M, MMA_N)\n    zeros!(tCrC)\n\n    # Retile\n    smem_thr_copy_A = get_slice(smem_copy_A, threadIdx().x)   \n    smem_thr_copy_B = get_slice(smem_copy_B, threadIdx().x)   \n    tCsA_retiled = partition_S(smem_thr_copy_A, sA)         # (MMA, MMA_M, MMA_K, 2)   \n    tCsB_retiled = partition_S(smem_thr_copy_B, sB)         # (MMA, MMA_N, MMA_K, 2)      \n    tCrA_retiled = retile_D(smem_thr_copy_A, tCrA)          # (MMA, MMA_M, MMA_K)    \n    tCrB_retiled = retile_D(smem_thr_copy_B, tCrB)          # (MMA, MMA_N, MMA_K)    \n\n    cp_async_wait()\n    sync_threads()\n\n    # Copy smem to rmem for k_block=1\n    smem_read = 1\n    smem_write = 2\n    tCsA_p = view(tCsA_retiled, :, :, :, smem_read)\n    tCsB_p = view(tCsB_retiled, :, :, :, smem_read)\n    copyto!(smem_copy_A, tCrA_retiled[:, :, _1], tCsA_p[:, :, _1])\n    copyto!(smem_copy_B, tCrB_retiled[:, :, _1], tCsB_p[:, :, _1])\n\n    k_tile_max = size(tAgA, 4)\n    k_block_max = static_size(tCrA, 3)\n    for k_tile in 1:k_tile_max\n        @loopinfo unroll for k_block in _1:k_block_max\n            k_block_next = k_block + 1 \n            if k_block == k_block_max\n                cp_async_wait()\n                sync_threads()\n                tCsA_p = view(tCsA_retiled, :, :, :, smem_read)\n                tCsB_p = view(tCsB_retiled, :, :, :, smem_read)\n                k_block_next = 1\n            end\n            \n            copyto!(smem_copy_A, tCrA_retiled[:, :, k_block_next], tCsA_p[:, :, k_block_next])\n            copyto!(smem_copy_B, tCrB_retiled[:, :, k_block_next], tCsB_p[:, :, k_block_next])   \n\n            if k_block == _1 && k_tile<k_tile_max\n                copyto!(gmem_copy_A, tAsA[:, :, :, smem_write], tAgA[:, :, :, k_tile+1])\n                copyto!(gmem_copy_B, tBsB[:, :, :, smem_write], tBgB[:, :, :, k_tile+1])\n                smem_read, smem_write = smem_write, smem_read\n            end\n            \n            @gc_preserve gemm!(mma, tCrC, tCrA[:, :, k_block], tCrB[:, :, k_block], tCrC)\n        end\n    end\n\n    copyto!(tCgC, tCrC)\n    sync_threads()\n    return nothing\nend\n\n\nfunction matmul(A, B, C)\n    bM = _128\n    bN = _128\n    bK = _16\n\n    TA = eltype(A)\n    TB = eltype(B)\n    TC = eltype(C)\n\t\n    mma = make_tiled_mma(MMAOP_16x8x8_F32TF32TF32F32_TN(), \n                         @Layout((2,2,1), (2,1,1)),\n                         (_32,_32,_8))\n\n    gmem_copy_A = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{UInt128}, TA}(),\n                                  @Layout((16, 8)),\n                                  @Layout((4, 1)))\n    gmem_copy_B = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{UInt128}, TB}(),\n                                  @Layout((32, 4), (4, 1)),\n                                  @Layout((1, 4)))\n\n    # A is M-major, so we cannot use LDSM_U32x4_N \n    smem_copy_A = make_tiled_copy_A(CopyAtom{UniversalCopy{TA}, TA}(), mma)\n    smem_copy_B = make_tiled_copy_B(CopyAtom{LDSM_U32x4_N, TB}(), mma)\n\n    sA_layout = @Layout (128, 16, 2) (1, 128, 2048)\n    sB_layout = @Layout (128, 16, 2) (16, 1,  2048)\n \n    threads = Int(size(mma))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, gmem_copy_A, smem_copy_A,\n                                                      B, sB_layout, gmem_copy_B, smem_copy_B,\n                                                      C, mma)\nend\n\n\nfunction test()\n    A = CUDA.randn(Float32, 2048, 256)   # M-major\n    B = CUDA.randn(Float32, 256, 2048)   # K-major\n    C =  CUDA.randn(Float32, 2048, 2048)\n    matmul(A, B', C)\n    CUDA.synchronize()\n    @test C == A * B\n    CUDA.unsafe_free!(A)\n    CUDA.unsafe_free!(B)\n    CUDA.unsafe_free!(C)\nend\n\ntest()","category":"page"},{"location":"api/layout/#Layout","page":"Layout","title":"Layout","text":"","category":"section"},{"location":"api/layout/#Index","page":"Layout","title":"Index","text":"","category":"section"},{"location":"api/layout/","page":"Layout","title":"Layout","text":"Pages = [\"layout.md\"]","category":"page"},{"location":"api/layout/#Constructors","page":"Layout","title":"Constructors","text":"","category":"section"},{"location":"api/layout/#MoYe.Layout","page":"Layout","title":"MoYe.Layout","text":"Layout{N, Shape, Stride}\n\nA Layout is a pair of Shape and Stride tuples.  The Shape tuple contains the number of elements in each dimension, and the Stride tuple contains the number of elements to skip to get to the next element in each dimension.\n\nFields\n\nshape.\nstride.\n\nIndexing\n\nA Layout can be indexed with three types of indices:\n\nInt: a linear index in a column-major order.\nIntTuple: a hierarchical index. It has the exact hierarchical structure as defined by the Shape.\nIntTuple: a congruent index. A tuple of N mixes hierarchical and linear indices along each dimension.\n\nExamples\n\njulia> layout = Layout((4, (2, 2)), (2, (1, 8)));\n\njulia> print_layout(ans)\n(4, (2, 2)):(2, (1, 8))\n       1    2    3    4\n    +----+----+----+----+\n 1  |  1 |  2 |  9 | 10 |\n    +----+----+----+----+\n 2  |  3 |  4 | 11 | 12 |\n    +----+----+----+----+\n 3  |  5 |  6 | 13 | 14 |\n    +----+----+----+----+\n 4  |  7 |  8 | 15 | 16 |\n    +----+----+----+----+\n\njulia> layout(6) # linear index\n4\n\njulia> layout((2,2)) # hierarchical index\n4\n\njulia> layout((2,(2,1))) # congruent index\n4\n\n\n\n\n\n","category":"type"},{"location":"api/layout/#MoYe.@Layout","page":"Layout","title":"MoYe.@Layout","text":"@Layout(shape, stride=nothing)\n\nConstruct a static layout with the given shape and stride.\n\nArguments\n\nshape: a tuple of integers or a single integer\nstride: a tuple of integers, a single integer, GenColMajor or GenRowMajor\n\n\n\n\n\n","category":"macro"},{"location":"api/layout/#MoYe.make_layout","page":"Layout","title":"MoYe.make_layout","text":"make_layout(shape::IntTuple, stride::IntTuple)\nmake_layout(shape::IntTuple, major=GenColMajor)\n\nConstruct a layout with the given shape and stride. If the stride is not given, it is set to col-major compact stride. See alse GenColMajor and GenRowMajor.\n\n\n\n\n\nmake_layout(::Layouts...)\n\nConcatenate layouts into a single layout.\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#Fundamentals","page":"Layout","title":"Fundamentals","text":"","category":"section"},{"location":"api/layout/#Base.size-Tuple{Layout}","page":"Layout","title":"Base.size","text":"size(::Layout)\nsize(::Layout, i::Union{Int, StaticInt})\n\nGet the cardinality of the domain of the layout. See also cosize.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#MoYe.rank-Tuple{Layout}","page":"Layout","title":"MoYe.rank","text":"rank(::Layout)\nrank(::Layout, i::Union{Int, StaticInt})\n\nGet the rank, i.e., the dimensionality, of the layout.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#MoYe.depth-Tuple{Layout}","page":"Layout","title":"MoYe.depth","text":"depth(::Layout)\ndepth(::Layout, i::Union{Int, StaticInt})\n\nGet the depth of the hierarchy of the layout. For example, the depth of (1,2) is 1, and the depth of ((1,2),3) is 2.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#MoYe.cosize-Tuple{Layout}","page":"Layout","title":"MoYe.cosize","text":"cosize(::Layout)\ncosize(::Layout, i::Union{Int, StaticInt})\n\nGet the cardinality of the codomain of the layout. See also size.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#Base.getindex-Tuple{Layout, Vararg{Union{Int32, Int64, Static.StaticInt}}}","page":"Layout","title":"Base.getindex","text":"getindex(layout::Layout, Is...)\n\nGet the sub-layout of layout with the given indices.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#Compact-Layout","page":"Layout","title":"Compact Layout","text":"","category":"section"},{"location":"api/layout/#MoYe.GenColMajor","page":"Layout","title":"MoYe.GenColMajor","text":"GenColMajor\n\nmake_layout uses this to create a col-major compact layout.\n\njulia> make_layout(((1, (2, 4)), 1), MoYe.GenColMajor)\n((1, (2, 4)), 1):((_1, (1, 2)), 8)\n\n\n\n\n\n","category":"type"},{"location":"api/layout/#MoYe.GenRowMajor","page":"Layout","title":"MoYe.GenRowMajor","text":"GenRowMajo\n\nmake_layout uses this to create a row-major compact layout.\n\njulia> make_layout(((1, (2, 4)), 1), MoYe.GenRowMajor)\n((1, (2, 4)), 1):((8, (4, 1)), _1)\n\n\n\n\n\n","category":"type"},{"location":"api/layout/#Algebra","page":"Layout","title":"Algebra","text":"","category":"section"},{"location":"api/layout/#Concatenation","page":"Layout","title":"Concatenation","text":"","category":"section"},{"location":"api/layout/#Base.cat-Tuple{Vararg{Layout}}","page":"Layout","title":"Base.cat","text":"cat(::Layouts...)\n\nConcatenate layouts into a single layout.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#MoYe.make_layout-Tuple{Vararg{Layout}}","page":"Layout","title":"MoYe.make_layout","text":"make_layout(::Layouts...)\n\nConcatenate layouts into a single layout.\n\n\n\n\n\n","category":"method"},{"location":"api/layout/#Composition","page":"Layout","title":"Composition","text":"","category":"section"},{"location":"api/layout/#MoYe.composition","page":"Layout","title":"MoYe.composition","text":"composition(l1::Layout, l2::Layout)\n\nCompose two layouts as composing two functions. You can use ∘ operator as well.\n\nExamples\n\njulia> make_layout(20, 2) ∘ make_layout((4, 5), (1, 4))\n(4, 5):(2, 8)\n\n\njulia> make_layout(20, 2) ∘ make_layout((4, 5), (5, 1))\n(4, 5):(10, 2)\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#Complement","page":"Layout","title":"Complement","text":"","category":"section"},{"location":"api/layout/#MoYe.complement","page":"Layout","title":"MoYe.complement","text":"complement(l::Layout, cosize::IntType)\n\nA complement layout of A is a layout B such that (A, B) is a compact layout of size cosize.\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#Inverse","page":"Layout","title":"Inverse","text":"","category":"section"},{"location":"api/layout/#MoYe.left_inverse","page":"Layout","title":"MoYe.left_inverse","text":"left_inverse(layout::Layout)\n\nReturn the left inverse of layout, i.e. a layout layout′ such that (layout′ ∘ layout)(i) == (i). The domain of layout′ is chosen to be the maximum continues squence of the domain of layout.\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#MoYe.right_inverse","page":"Layout","title":"MoYe.right_inverse","text":"right_inverse(layout::Layout)\n\nReturn the right inverse of layout, i.e. a layout layout′ such that (layout ∘ layout′)(i) == (i). The domain of layout′ is chosen to be the maximum continues squence of the codomain of layout.\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#Product","page":"Layout","title":"Product","text":"","category":"section"},{"location":"api/layout/#MoYe.logical_product","page":"Layout","title":"MoYe.logical_product","text":"logical_product(A::Layout, B::Layout)\n\nCompute the logical product of two layouts. Indexing through the first mode of the resulting layout corresponds to indexing through A and indexing through the second mode corresponds to indexing through B.\n\njulia> tile = @Layout((2, 2), (1, 2));\n\njulia> print_layout(tile)\n(_2, _2):(_1, _2)\n      1   2\n    +---+---+\n 1  | 1 | 3 |\n    +---+---+\n 2  | 2 | 4 |\n    +---+---+\n\njulia> matrix_of_tiles = @Layout((3, 4), (4, 1));\n\njulia> print_layout(matrix_of_tiles)\n(_3, _4):(_4, _1)\n       1    2    3    4\n    +----+----+----+----+\n 1  |  1 |  2 |  3 |  4 |\n    +----+----+----+----+\n 2  |  5 |  6 |  7 |  8 |\n    +----+----+----+----+\n 3  |  9 | 10 | 11 | 12 |\n    +----+----+----+----+\n\njulia> print_layout(logical_product(tile, matrix_of_tiles))\n((_2, _2), (_3, _4)):((_1, _2), (_16, _4))\n       1    2    3    4    5    6    7    8    9   10   11   12\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 1  |  1 | 17 | 33 |  5 | 21 | 37 |  9 | 25 | 41 | 13 | 29 | 45 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 2  |  2 | 18 | 34 |  6 | 22 | 38 | 10 | 26 | 42 | 14 | 30 | 46 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 3  |  3 | 19 | 35 |  7 | 23 | 39 | 11 | 27 | 43 | 15 | 31 | 47 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 4  |  4 | 20 | 36 |  8 | 24 | 40 | 12 | 28 | 44 | 16 | 32 | 48 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#MoYe.blocked_product","page":"Layout","title":"MoYe.blocked_product","text":"blocked_product(tile::Layout, matrix_of_tiles::Layout, coalesce_result::Bool=false)\n\nCompute the blocked product of two layouts. Indexing through the first mode of the resulting layout corresponds to indexing through the cartesian product of the first mode of tile and the first mode of matrix_of_tiles. Indexing through the second mode is similar. If coalesce_result is true, then the result is coalesced.\n\njulia> tile = @Layout (2, 2);\n\njulia> matrix_of_tiles = @Layout (3, 4) (4, 1);\n\njulia> print_layout(blocked_product(tile, matrix_of_tiles))\n((_2, _3), (_2, _4)):((_1, _16), (_2, _4))\n       1    2    3    4    5    6    7    8\n    +----+----+----+----+----+----+----+----+\n 1  |  1 |  3 |  5 |  7 |  9 | 11 | 13 | 15 |\n    +----+----+----+----+----+----+----+----+\n 2  |  2 |  4 |  6 |  8 | 10 | 12 | 14 | 16 |\n    +----+----+----+----+----+----+----+----+\n 3  | 17 | 19 | 21 | 23 | 25 | 27 | 29 | 31 |\n    +----+----+----+----+----+----+----+----+\n 4  | 18 | 20 | 22 | 24 | 26 | 28 | 30 | 32 |\n    +----+----+----+----+----+----+----+----+\n 5  | 33 | 35 | 37 | 39 | 41 | 43 | 45 | 47 |\n    +----+----+----+----+----+----+----+----+\n 6  | 34 | 36 | 38 | 40 | 42 | 44 | 46 | 48 |\n    +----+----+----+----+----+----+----+----+\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#MoYe.raked_product","page":"Layout","title":"MoYe.raked_product","text":"raked_product(tile::Layout, matrix_of_tiles::Layout, coalesce_result::Bool=false)\n\nThe tile is shattered or interleaved with the matrix of tiles.\n\njulia> tile = @Layout (2, 2) (1, 2);\n\njulia> matrix_of_tiles = @Layout (3, 4) (4, 1);\n\njulia> print_layout(raked_product(tile, matrix_of_tiles))\n((_3, _2), (_4, _2)):((_16, _1), (_4, _2))\n       1    2    3    4    5    6    7    8\n    +----+----+----+----+----+----+----+----+\n 1  |  1 |  5 |  9 | 13 |  3 |  7 | 11 | 15 |\n    +----+----+----+----+----+----+----+----+\n 2  | 17 | 21 | 25 | 29 | 19 | 23 | 27 | 31 |\n    +----+----+----+----+----+----+----+----+\n 3  | 33 | 37 | 41 | 45 | 35 | 39 | 43 | 47 |\n    +----+----+----+----+----+----+----+----+\n 4  |  2 |  6 | 10 | 14 |  4 |  8 | 12 | 16 |\n    +----+----+----+----+----+----+----+----+\n 5  | 18 | 22 | 26 | 30 | 20 | 24 | 28 | 32 |\n    +----+----+----+----+----+----+----+----+\n 6  | 34 | 38 | 42 | 46 | 36 | 40 | 44 | 48 |\n    +----+----+----+----+----+----+----+----+\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#Division","page":"Layout","title":"Division","text":"","category":"section"},{"location":"api/layout/#MoYe.logical_divide","page":"Layout","title":"MoYe.logical_divide","text":"logical_divide(layout::Layout, tile::Tile)\n\nGather the elements of layout along all modes into blocks according to tile.\n\njulia> raked_prod = @Layout ((3, 2), (4, 2)) ((16, 1), (4, 2));\n\njulia> print_layout(raked_prod)\n((_3, _2), (_4, _2)):((_16, _1), (_4, _2))\n       1    2    3    4    5    6    7    8\n    +----+----+----+----+----+----+----+----+\n 1  |  1 |  5 |  9 | 13 |  3 |  7 | 11 | 15 |\n    +----+----+----+----+----+----+----+----+\n 2  | 17 | 21 | 25 | 29 | 19 | 23 | 27 | 31 |\n    +----+----+----+----+----+----+----+----+\n 3  | 33 | 37 | 41 | 45 | 35 | 39 | 43 | 47 |\n    +----+----+----+----+----+----+----+----+\n 4  |  2 |  6 | 10 | 14 |  4 |  8 | 12 | 16 |\n    +----+----+----+----+----+----+----+----+\n 5  | 18 | 22 | 26 | 30 | 20 | 24 | 28 | 32 |\n    +----+----+----+----+----+----+----+----+\n 6  | 34 | 38 | 42 | 46 | 36 | 40 | 44 | 48 |\n    +----+----+----+----+----+----+----+----+\n\njulia> subtile = (Layout(2, 3), Layout(2, 4)); # gather 2 elements with stride 3 along the first mode\n       # and 2 elements with stride 4 along the second mode\n\njulia> print_layout(logical_divide(raked_prod, subtile))\n(((1, 2), ((3, 1), (1, 1))), ((1, 2), ((4, 1), (1, 1)))):(((48, 1), ((_16, _1), (48, 2))), ((16, 2), ((_4, _2), (16, 4))))\n       1    2    3    4    5    6    7    8\n    +----+----+----+----+----+----+----+----+\n 1  |  1 |  3 |  5 |  7 |  9 | 11 | 13 | 15 |\n    +----+----+----+----+----+----+----+----+\n 2  |  2 |  4 |  6 |  8 | 10 | 12 | 14 | 16 |\n    +----+----+----+----+----+----+----+----+\n 3  | 17 | 19 | 21 | 23 | 25 | 27 | 29 | 31 |\n    +----+----+----+----+----+----+----+----+\n 4  | 18 | 20 | 22 | 24 | 26 | 28 | 30 | 32 |\n    +----+----+----+----+----+----+----+----+\n 5  | 33 | 35 | 37 | 39 | 41 | 43 | 45 | 47 |\n    +----+----+----+----+----+----+----+----+\n 6  | 34 | 36 | 38 | 40 | 42 | 44 | 46 | 48 |\n    +----+----+----+----+----+----+----+----+\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#MoYe.zipped_divide","page":"Layout","title":"MoYe.zipped_divide","text":"zipped_divide(layout::Layout, tile)\n\nCompute the logical division of layout by tile, then group the resulting subtiles into the first mode and the rest into the second mode.\n\njulia> raked_prod = @Layout ((3, 2), (4, 2)) ((16, 1), (4, 2));\n\njulia> print_layout(raked_prod)\n((_3, _2), (_4, _2)):((_16, _1), (_4, _2))\n       1    2    3    4    5    6    7    8\n    +----+----+----+----+----+----+----+----+\n 1  |  1 |  5 |  9 | 13 |  3 |  7 | 11 | 15 |\n    +----+----+----+----+----+----+----+----+\n 2  | 17 | 21 | 25 | 29 | 19 | 23 | 27 | 31 |\n    +----+----+----+----+----+----+----+----+\n 3  | 33 | 37 | 41 | 45 | 35 | 39 | 43 | 47 |\n    +----+----+----+----+----+----+----+----+\n 4  |  2 |  6 | 10 | 14 |  4 |  8 | 12 | 16 |\n    +----+----+----+----+----+----+----+----+\n 5  | 18 | 22 | 26 | 30 | 20 | 24 | 28 | 32 |\n    +----+----+----+----+----+----+----+----+\n 6  | 34 | 38 | 42 | 46 | 36 | 40 | 44 | 48 |\n    +----+----+----+----+----+----+----+----+\n\njulia> subtile = (@Layout(2, 3), @Layout(2, 4)); # gather 2 elements with stride 3 along the first mode and 2 elements with stride 4 along the second mode\n\njulia> print_layout(zipped_divide(raked_prod, subtile))\n((_2, _2), (_3, _4)):((_1, _2), (_16, _4))\n       1    2    3    4    5    6    7    8    9   10   11   12\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 1  |  1 | 17 | 33 |  5 | 21 | 37 |  9 | 25 | 41 | 13 | 29 | 45 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 2  |  2 | 18 | 34 |  6 | 22 | 38 | 10 | 26 | 42 | 14 | 30 | 46 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 3  |  3 | 19 | 35 |  7 | 23 | 39 | 11 | 27 | 43 | 15 | 31 | 47 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n 4  |  4 | 20 | 36 |  8 | 24 | 40 | 12 | 28 | 44 | 16 | 32 | 48 |\n    +----+----+----+----+----+----+----+----+----+----+----+----+\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#MoYe.tiled_divide","page":"Layout","title":"MoYe.tiled_divide","text":"tiled_divide(layout::Layout, tile)\n\nSimilar to zipped_divide, but upack the second mode into multiple modes.\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#Miscellaneous","page":"Layout","title":"Miscellaneous","text":"","category":"section"},{"location":"api/layout/#Base.coalesce","page":"Layout","title":"Base.coalesce","text":"coalesce(layout::Layout)\n\nCoalesce the layout by merging adjacent dimensions with stride 1.\n\nExamples\n\njulia> layout = @Layout (2, (1, 6)) (1, (6, 2))\n(_2, (_1, _6)):(_1, (_6, _2))\n\n\njulia> print(coalesce(layout))\n_12:_1\n\n\n\n\n\n","category":"function"},{"location":"api/layout/#MoYe.flatten-Tuple{Layout}","page":"Layout","title":"MoYe.flatten","text":"flatten(layout::Layout)\n\nRemove the hierarchy of the layout and make it a flat layout.\n\nExamples\n\njulia> layout = make_layout(((4, 3), 1), ((3, 1), 0))\n((4, 3), 1):((3, 1), 0)\n\n\njulia> print(flatten(layout))\n(4, 3, 1):(3, 1, 0)\n\n\n\n\n\n","category":"method"},{"location":"api/atom/#MMA/Copy-Atom","page":"MMA/Copy Atoms","title":"MMA/Copy Atom","text":"","category":"section"},{"location":"api/atom/#Index","page":"MMA/Copy Atoms","title":"Index","text":"","category":"section"},{"location":"api/atom/","page":"MMA/Copy Atoms","title":"MMA/Copy Atoms","text":"Pages = [\"atom.md\"]","category":"page"},{"location":"api/atom/#MoYe.make_tiled_mma","page":"MMA/Copy Atoms","title":"MoYe.make_tiled_mma","text":"make_tiled_mma(mma_op, atom_layout, permutations)\n\nCreate a TiledMMA object from an MMA operation, atom layout, and permutations. See also print_typst.\n\nArguments\n\nmma_op::OP: The MMA operation.\natom_layout::Layout: The layout of the atom.\npermutations::Tile: The permutations of the atom.\n\nExamples\n\njulia> tiled_mma = make_tiled_mma(MMAOP_8x8x4_F32F16F16F32_NT(), @Layout((2,2), (2,1)), (@Layout((4,4,2), (1,8,4)), _32, _4))\nTiledMMA\n  ThrLayoutVMNK: ((_4, _2), _2, _2, _1):((_1, _16), _8, _4, _0)\n  PermutationMNK: ((_4, _4, _2):(_1, _8, _4), _32, _4)\nMMAAtom\n  Thread ID: (_4, _2):(_1, _16)\n  Layout_A_TV: ((_4, _2), _4):((_8, _4), _1)\n  Layout_B_TV: ((_4, _2), _4):((_8, _4), _1)\n  Layout_C_TV: ((_2, _2, _2), (_2, _2, _2)):((_1, _16, _4), (_8, _2, _32))\n\n\n\n\n\n\n","category":"function"},{"location":"api/atom/#MoYe.make_tiled_copy","page":"MMA/Copy Atoms","title":"MoYe.make_tiled_copy","text":"make_tiled_copy(copy_atom::CopyAtom,\n                thr_layout::Layout,\n                val_layout::Layout)\n\nMake a tiled copy atom from a copy atom.\n\n\n\n\n\n","category":"function"},{"location":"api/atom/#MoYe.print_typst","page":"MMA/Copy Atoms","title":"MoYe.print_typst","text":"print_typst(::AbstractMMAAtom)\n\nPrint the layout of the A, B, and C matrices in a typst format. Go to https://typst.app and paste the output to visualize the layout.\n\nExample\n\njulia> tiled_mma = make_tiled_mma(MMAOP_8x8x4_F32F16F16F32_NT(), @Layout((2,2), (2,1)), (@Layout((4,4,2), (1,8,4)), _32, _4))\nTiledMMA\n  ThrLayoutVMNK: ((_4, _2), _2, _2, _1):((_1, _16), _8, _4, _0)\n  PermutationMNK: ((_4, _4, _2):(_1, _8, _4), _32, _4)\nMMAAtom\n  Thread ID: (_4, _2):(_1, _16)\n  Layout_A_TV: ((_4, _2), _4):((_8, _4), _1)\n  Layout_B_TV: ((_4, _2), _4):((_8, _4), _1)\n  Layout_C_TV: ((_2, _2, _2), (_2, _2, _2)):((_1, _16, _4), (_8, _2, _32))\n\n\njulia> print_typst(tiled_mma)\n\nIt will print the following image: (Image: )\n\n\n\n\n\nprint_typst(::AbstractCopyAtom)\n\nPrint the layout of the source and destination matrices in a typst format.\n\nExample\n\njulia> tiled_copy = make_tiled_copy(CopyAtom{UniversalCopy{UInt128}, Float32}(), \n                                    @Layout((32,8)), \n                                    @Layout((4,1)))\n\njulia> print_typst(tiled_copy)\n\n\n\n\n\n","category":"function"},{"location":"manual/layout/#Layout","page":"Layout","title":"Layout","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"A Layout defines how multidimensional data is stored in one-dimensional memory. It maps a logical coordinate to a linear index using a shape and a stride. The shape defines the dimensions of the array, while the stride determines the memory offset for each dimension.","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"For example, let's create a vector with a stride of 2:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"using MoYe\nstruct StrideVector\n   data\n   layout\nend\n\nBase.getindex(x::StrideVector, i) = x.data[x.layout(i)]\na = StrideVector(collect(1:8), Layout(4, 2))\n@show a[1] a[2] a[3] a[4];","category":"page"},{"location":"manual/layout/#Fundamentals","page":"Layout","title":"Fundamentals","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"using MoYe\nlayout_2x4 = Layout((2, (2, 2)), (4, (1, 2)))\nprint(\"Shape: \", shape(layout_2x4))\nprint(\"Stride: \", stride(layout_2x4))\nprint(\"Size: \", size(layout_2x4)) # The domain is 1:8\nprint(\"Rank: \", rank(layout_2x4))\nprint(\"Depth: \", depth(layout_2x4))\nprint(\"Cosize: \", cosize(layout_2x4)) \nlayout_2x4 # This can be viewed as a row-major matrix","category":"page"},{"location":"manual/layout/#Compile-Time-vs.-Dynamic-Layouts","page":"Layout","title":"Compile-Time vs. Dynamic Layouts","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"You can also use static integers for compile-time layouts:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"static_layout = @Layout (2, (2, 2)) (4, (1, 2))\ntypeof(static_layout)\nsizeof(static_layout)\n","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"Static and dynamic layouts can produce different-looking but mathematically equivalent results. For example:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"layout = @Layout (2, (1, 6)) (1, (6, 2)) \nprint(coalesce(layout))","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"is different from:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"layout = Layout((2, (1, 6)), (1, (6, 2))) \nprint(coalesce(layout))","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"Static layouts allow for more aggressive compile-time simplification, while dynamic layouts may lead to type instability due to runtime checks.","category":"page"},{"location":"manual/layout/#Coordinate-Spaces","page":"Layout","title":"Coordinate Spaces","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"A Layout's coordinate space is determined by its Shape and can be viewed in three ways:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"h-D (Hierarchical) Coordinate Space: Each element has the same hierarchical structure as the Shape.\n1-D Coordinate Space: The colexicographically flattened, one-dimensional representation of the coordinate space.\nR-D Coordinate Space: Each element has the same rank as the Shape, but each top-level axis is colexicographically flattened into a one-dimensional space. R is the rank of the layout.","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"layout_2x4(2, (1, 2)) # h-D coordinate\nlayout_2x4(2, 3)      # R-D coordinate\nlayout_2x4(6)         # 1-D coordinate","category":"page"},{"location":"manual/layout/#Layout-Algebra","page":"Layout","title":"Layout Algebra","text":"","category":"section"},{"location":"manual/layout/#Concatenation","page":"Layout","title":"Concatenation","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"A Layout can be expressed as the concatenation of its sub-layouts.","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"layout_2x4[2] # Get the second sub-layout\ntuple(layout_2x4...) # Splat a layout into its sub-layouts\nmake_layout(layout_2x4...) # Concatenate sub-layouts\nfor sublayout in layout_2x4 # Iterate over sub-layouts\n   @show sublayout\nend","category":"page"},{"location":"manual/layout/#Complement","page":"Layout","title":"Complement","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"Let's partition a vector of 24 elements into six tiles of four elements each, gathering every fourth element at even indices.","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"This operation creates a new layout where we collect every second element until we have four, then repeat this for the rest of the vector.","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"The resulting layout would resemble:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"       1    2    3    4    5    6\n    +----+----+----+----+----+----+\n 1  |  1 |  2 |  9 | 10 | 17 | 18 |\n    +----+----+----+----+----+----+\n 2  |  3 |  4 | 11 | 12 | 19 | 20 |\n    +----+----+----+----+----+----+\n 3  |  5 |  6 | 13 | 14 | 21 | 22 |\n    +----+----+----+----+----+----+\n 4  |  7 |  8 | 15 | 16 | 23 | 24 |\n    +----+----+----+----+----+----+","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"complement computes the first row of this new layout.","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"print_layout(complement(@Layout(4,2), 24))","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"The Layout(4,2) and its complement give us the desired new layout:","category":"page"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"print_layout(make_layout(@Layout(4, 2),complement(@Layout(4, 2), 24)))","category":"page"},{"location":"manual/layout/#Product","page":"Layout","title":"Product","text":"","category":"section"},{"location":"manual/layout/#Logical-Product","page":"Layout","title":"Logical Product","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"tile = @Layout((2,2), (1,2));\nprint_layout(tile)\nmatrix_of_tiles = @Layout((3,4), (4,1));\nprint_layout(matrix_of_tiles)\nprint_layout(logical_product(tile, matrix_of_tiles))","category":"page"},{"location":"manual/layout/#Blocked-Product","page":"Layout","title":"Blocked Product","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"print_layout(blocked_product(tile, matrix_of_tiles))","category":"page"},{"location":"manual/layout/#Raked-Product","page":"Layout","title":"Raked Product","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"print_layout(raked_product(tile, matrix_of_tiles))","category":"page"},{"location":"manual/layout/#Division","page":"Layout","title":"Division","text":"","category":"section"},{"location":"manual/layout/#Logical-Division","page":"Layout","title":"Logical Division","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"raked_prod = raked_product(tile, matrix_of_tiles);\nsubtile = (@Layout(2,3), @Layout(2,4));\nprint_layout(logical_divide(raked_prod, subtile))","category":"page"},{"location":"manual/layout/#Zipped-Division","page":"Layout","title":"Zipped Division","text":"","category":"section"},{"location":"manual/layout/","page":"Layout","title":"Layout","text":"print_layout(zipped_divide(raked_prod, subtile))","category":"page"},{"location":"api/copy/#Data-Movement","page":"Data Movement","title":"Data Movement","text":"","category":"section"},{"location":"api/copy/#Index","page":"Data Movement","title":"Index","text":"","category":"section"},{"location":"api/copy/","page":"Data Movement","title":"Data Movement","text":"Pages = [\"copy.md\"]","category":"page"},{"location":"api/copy/#Base.copyto!-Tuple{MoYeArray, MoYeArray}","page":"Data Movement","title":"Base.copyto!","text":"copyto!(dest::MoYeArray, src::MoYeArray)\n\nCopy the contents of src to dest. The function automatically carries out potential vectorization. In particular, while transferring data from global memory to shared memory, it automatically initiates asynchronous copying, if your device supports so.\n\n\n\n\n\n","category":"method"},{"location":"api/copy/#Base.copyto!-Tuple{MoYe.AbstractLdMatrix, MoYeArray, MoYeArray}","page":"Data Movement","title":"Base.copyto!","text":"copyto!(ldmatrix::AbstractLdMatrix, dest::MoYeArray{UInt32}, src::MoYeArray{UInt128})\n\nLoad data from shared memory to registers. The available AbstractLdMatrixs are:\n\n# Type => LLVM intrinsic\n\"LDSM_U32x1_N\" => \"llvm.nvvm.ldmatrix.sync.aligned.m8n8.x1.b16\"\n\"LDSM_U32x2_N\" => \"llvm.nvvm.ldmatrix.sync.aligned.m8n8.x2.b16\"\n\"LDSM_U32x4_N\" => \"llvm.nvvm.ldmatrix.sync.aligned.m8n8.x4.b16\"\n\"LDSM_U16x2_T\" => \"llvm.nvvm.ldmatrix.sync.aligned.m8n8.x1.trans.b16\"\n\"LDSM_U16x4_T\" => \"llvm.nvvm.ldmatrix.sync.aligned.m8n8.x2.trans.b16\"\n\"LDSM_U16x8_T\" => \"llvm.nvvm.ldmatrix.sync.aligned.m8n8.x4.trans.b16\"\n\nYou can inspect the number and the type of  registers used per thread by\n\njulia> LDSM_U32x4_N()\nLDSM_U32x4_N()\n\njulia> ans.DRegisters\nRegisters{UInt32, 4}\n\n\n\n\n\n","category":"method"},{"location":"api/copy/#MoYe.cp_async_wait","page":"Data Movement","title":"MoYe.cp_async_wait","text":"cp_async_wait(N::Int32)\ncp_async_wait()\n\ncp_async_wait(N) is equivalent to cp.async.wait.group(N) and cp_async_wait() is equivalent to cp.async.wait.all in CUDA.\n\n\n\n\n\n","category":"function"},{"location":"api/copy/#MoYe.cp_async_commit","page":"Data Movement","title":"MoYe.cp_async_commit","text":"cp_async_commit()\n\ncp.async.commit.group.\n\n\n\n\n\n","category":"function"},{"location":"#MoYe","page":"Home","title":"MoYe","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for MoYe.","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"julia> data = [i for i in 1:48];\n\njulia> a = MoYeArray(data, @Layout((6,8)))\n6×8 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{6}, Static.StaticInt{8}}, Tuple{Static.StaticInt{1}, Static.StaticInt{6}}}} with indices _1:_6×_1:_8:\n 1   7  13  19  25  31  37  43\n 2   8  14  20  26  32  38  44\n 3   9  15  21  27  33  39  45\n 4  10  16  22  28  34  40  46\n 5  11  17  23  29  35  41  47\n 6  12  18  24  30  36  42  48\n\njulia> subtile_a = @tile a (_3, _4) (1, 2)\n3×4 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{3}, Static.StaticInt{4}}, Tuple{Static.StaticInt{1}, Static.StaticInt{6}}}} with indices _1:_3×_1:_4:\n 25  31  37  43\n 26  32  38  44\n 27  33  39  45\n\njulia> workitems_a = @parallelize subtile_a (_3, _2) (1, 1)\n1×2 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{1}, Static.StaticInt{2}}, Tuple{Static.StaticInt{0}, Static.StaticInt{12}}}} with indices _1:_1×_1:_2:\n 25  37\n\njulia> for i in eachindex(workitems_a)\n                  workitems_a[i] = 0\n              end\n\njulia> a\n6×8 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{6}, Static.StaticInt{8}}, Tuple{Static.StaticInt{1}, Static.StaticInt{6}}}} with indices _1:_6×_1:_8:\n 1   7  13  19   0  31   0  43\n 2   8  14  20  26  32  38  44\n 3   9  15  21  27  33  39  45\n 4  10  16  22  28  34  40  46\n 5  11  17  23  29  35  41  47\n 6  12  18  24  30  36  42  48\n\njulia> @tile subtile_a (_3, _1) (1, 2)\n3×1 MoYeArray{Int64, 2, ViewEngine{Int64, Ptr{Int64}}, Layout{2, Tuple{Static.StaticInt{3}, Static.StaticInt{1}}, Tuple{Static.StaticInt{1}, Static.StaticInt{0}}}} with indices _1:_3×_1:_1:\n 31\n 32\n 33","category":"page"},{"location":"#Tile-Iterator","page":"Home","title":"Tile Iterator","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"using MoYe \ndata = collect(1:36);\nA = MoYeArray(data, @Layout((4,9)))\ntiled_A = zipped_divide(A, (@Layout(2), @Layout(3))) # 2 × 3 tile\nfor i in axes(tiled_A, 2)\n    @show view(tiled_A, :, i)\nend","category":"page"},{"location":"manual/pipeline/#Pipelining","page":"Pipeline","title":"Pipelining","text":"","category":"section"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"Instruction-level parallelism (ILP) is a technique used to improve the performance of processors by executing multiple instructions simultaneously. In the context of GPU programming, we can apply ILP to overlap memory operations with computation, effectively hiding memory latency.","category":"page"},{"location":"manual/pipeline/#Overlapping-Global-to-Shared-Copies-with-MMA-Computation","page":"Pipeline","title":"Overlapping Global-to-Shared Copies with MMA Computation","text":"","category":"section"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"We can overlap global-to-shared memory copies with MMA (Matrix Multiply-Accumulate) computation. This is achieved by prefetching the next tile of data from global memory into shared memory while the current tile is being processed.","category":"page"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"(Image: )","category":"page"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"To implement this, we explicitly load data from shared memory to registers for the MMA computation and initiate a new load from global memory to shared memory for the next tile before starting the computation.","category":"page"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"function matmul_kernel(A, sA_layout, copy_A,\n                       B, sB_layout, copy_B,\n                       C, mma_C)\n    sA = MoYeSharedArray(eltype(A), sA_layout)\n    sB = MoYeSharedArray(eltype(B), sB_layout)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Copy partition\n    thr_copy_a = get_slice(copy_A, threadIdx().x)      \n    tAgA = partition_S(thr_copy_a, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(thr_copy_a, sA)                 # (CPY, CPY_M, CPY_K)\n\n    thr_copy_b = get_slice(copy_B, threadIdx().x)\n    tBgB = partition_S(thr_copy_b, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(thr_copy_b, sB)                 # (CPY, CPY_N, CPY_K)\n\n    # Copy gmem to smem for k_tile=1\n    copyto!(copy_A, tAsA, view(tAgA, :, :, :, _1))\n    copyto!(copy_B, tBsB, view(tBgB, :, :, :, _1))\n\n    # MMA partition\n    thr_mma = get_slice(mma_C, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                    # (MMA, MMA_M, MMA_K)\n    tCsB = partition_B(thr_mma, sB)                    # (MMA, MMA_M, MMA_K)\n    tCgC = partition_C(thr_mma, gC)                    # (MMA, MMA_M, MMA_N)\n\n    # MMA registers\n    tCrA = make_fragment_A(thr_mma, tCsA)                # (MMA, MMA_M, MMA_K)\n    tCrB = make_fragment_B(thr_mma, tCsB)                # (MMA, MMA_N, MMA_K)\n    tCrC = make_fragment_C(thr_mma, tCgC)                # (MMA, MMA_M, MMA_N)\n    zeros!(tCrC)\n\n    k_max = size(tAgA, 4)\n    for k in 1:k_max\n        cp_async_wait()\n        sync_threads()\n\n        # Copy from smem to rmem\n        copyto!(tCrA, tCsA)\n        copyto!(tCrB, tCsB)\n        sync_threads()\n\n        if k < k_max\n            copyto!(copy_A, tAsA, view(tAgA, :, :, :, k+1))\n            copyto!(copy_B, tBsB, view(tBgB, :, :, :, k+1))\n        end\n\n        @gc_preserve gemm!(mma_C, tCrC, tCrA, tCrB, tCrC)\n    end\n\n    copyto!(tCgC, tCrC)\n    return nothing\nend","category":"page"},{"location":"manual/pipeline/#Double-Buffering","page":"Pipeline","title":"Double Buffering","text":"","category":"section"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"We can also overlap shared-to-register memory copies with MMA computation using a technique called double buffering.","category":"page"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"This involves allocating two shared memory buffers: one for the current computation and one for prefetching the next tile. We asynchronously prefetch the next tile from global memory to the second shared memory buffer while the first is being used for computation.","category":"page"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"(Image: matmuil)","category":"page"},{"location":"manual/pipeline/","page":"Pipeline","title":"Pipeline","text":"@views function matmul_kernel(A, sA_layout, copy_A,\n                              B, sB_layout, copy_B,\n                              C, mma_C)\n    sA = MoYeSharedArray(eltype(A), sA_layout)        # (bM, bK, 2)\n    sB = MoYeSharedArray(eltype(B), sB_layout)        # (bN, bK, 2)\n\n    mA = MoYeArray(A)\n    mB = MoYeArray(B)\n    mC = MoYeArray(C)\n\n    bM = size(sA_layout, 1)\n    bN = size(sB_layout, 1)\n    bK = size(sB_layout, 2)\n\n    gA = @tile mA (bM, bK) (blockIdx().x, :)\n    gB = @tile mB (bN, bK) (blockIdx().y, :)\n    gC = @tile mC (bM, bN) (blockIdx().x, blockIdx().y)\n\n    # Copy partition\n    thr_copy_a = get_slice(copy_A, threadIdx().x)      \n    tAgA = partition_S(thr_copy_a, gA)                 # (CPY, CPY_M, CPY_K, k)\n    tAsA = partition_D(thr_copy_a, sA)                 # (CPY, CPY_M, CPY_K, 2)\n\n    thr_copy_b = get_slice(copy_B, threadIdx().x)\n    tBgB = partition_S(thr_copy_b, gB)                 # (CPY, CPY_N, CPY_K, k)\n    tBsB = partition_D(thr_copy_b, sB)                 # (CPY, CPY_N, CPY_K, 2)\n\n    # Copy gmem to smem for k_tile=1\n    copyto!(copy_A, tAsA[:, :, :, 1], tAgA[:, :, :, _1])\n    copyto!(copy_B, tBsB[:, :, :, 1], tBgB[:, :, :, _1])\n\n    # MMA partition\n    thr_mma = get_slice(mma_C, threadIdx().x)\n    tCsA = partition_A(thr_mma, sA)                    # (MMA, MMA_M, MMA_K, 2)\n    tCsB = partition_B(thr_mma, sB)                    # (MMA, MMA_M, MMA_K, 2)\n    tCgC = partition_C(thr_mma, gC)                    # (MMA, MMA_M, MMA_N)\n\n    # MMA registers\n    tCrA = make_fragment_A(thr_mma, tCsA[:, :, :, _1])    # (MMA, MMA_M, MMA_K)\n    tCrB = make_fragment_B(thr_mma, tCsB[:, :, :, _1])    # (MMA, MMA_N, MMA_K)\n    tCrC = make_fragment_C(thr_mma, tCgC)                 # (MMA, MMA_M, MMA_N)\n    zeros!(tCrC)\n\n    cp_async_wait()\n    sync_threads()\n\n    # Copy smem to rmem for k_block=1\n    smem_read = 1\n    smem_write = 2\n    tCsA_p = view(tCsA, :, :, :, smem_read)\n    tCsB_p = view(tCsB, :, :, :, smem_read)\n    copyto!(tCrA[:, :, 1], tCsA_p[:, :, _1])\n    copyto!(tCrB[:, :, 1], tCsB_p[:, :, _1])\n\n    k_tile_max = size(tAgA, 4)\n    k_block_max = static_size(tCrA, 3)\n    for k_tile in 1:k_tile_max\n        @loopinfo unroll for k_block in _1:k_block_max\n            k_block_next = k_block + 1 \n            if k_block == k_block_max\n                cp_async_wait()\n                sync_threads()\n                tCsA_p = view(tCsA, :, :, :, smem_read)\n                tCsB_p = view(tCsB, :, :, :, smem_read)\n                k_block_next = 1\n            end\n            \n            copyto!(tCrA[:, :, k_block_next], tCsA_p[:, :, k_block_next])\n            copyto!(tCrB[:, :, k_block_next], tCsB_p[:, :, k_block_next])   \n\n            if k_block == _1 && k_tile<k_tile_max\n                copyto!(copy_A, tAsA[:, :, :, smem_write], tAgA[:, :, :, k_tile+1])\n                copyto!(copy_B, tBsB[:, :, :, smem_write], tBgB[:, :, :, k_tile+1])\n                smem_read, smem_write = smem_write, smem_read\n            end\n            \n            @gc_preserve gemm!(mma_C, tCrC, tCrA[:, :, k_block], tCrB[:, :, k_block], tCrC)\n        end\n    end\n\n    copyto!(tCgC, tCrC)\n    return nothing\nend\n\nfunction matmul(A, B, C)\n    bM = _128\n    bN = _128\n    bK = _8\n    \n    sA_layout = make_layout((bM, bK, _2), (_1, bM + _2, (bM + _2) * bK))\n    sB_layout = make_layout((bN, bK, _2), (_1, bN + _2, (bN + _2) * bK))\n\n    TA = eltype(A)\n    TB = eltype(B)\n    TC = eltype(C)\n\t\n    copy_A = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{Float64}, TA}(),\n                             @Layout((32, 8)),\n                             @Layout((2, 1)))\n    copy_B = make_tiled_copy(CopyAtom{CPOP_ASYNC_CACHEALWAYS{Float64}, TB}(),\n                             @Layout((32, 8)),\n                             @Layout((2, 1)))\n\n    mma_C = make_tiled_mma(UniversalFMA{TA,TB, TC}(), # MMA operation\n                           @Layout((32, 8)))          # Atom layout\n\n    threads = Int(size(mma_C))\n    blocks = (cld(size(A, 1), bM), cld(size(B, 1), bN))\n\n    @cuda threads=threads blocks=blocks matmul_kernel(A, sA_layout, copy_A,\n                                                      B, sB_layout, copy_B,\n                                                      C, mma_C)\nend\n\nfunction test()\n    A =  CUDA.randn(Float32, 2048, 256)\n    B =  CUDA.randn(Float32, 2048, 256)\n    C =  CUDA.randn(Float32, 2048, 2048)\n    matmul(A, B, C)\n    CUDA.synchronize()\n    @test C == A * B'\n    CUDA.unsafe_free!(A)\n    CUDA.unsafe_free!(B)\n    CUDA.unsafe_free!(C)\nend\n\ntest()","category":"page"}]
}
